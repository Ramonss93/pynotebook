{
 "metadata": {
  "name": "",
  "signature": "sha256:ef617264f9f6e15b0e641ab5104106233e3c3f06ff05d1fcc855416bc73a2a40"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Spatial interpolation of daily air temperature for China with complex topography and highly variable station density"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I used this paper from Stahl et al. (2006) where they compare different spatial interpolation methods for the same problem in Canada. I used Model 12: Gradient-plus-inverse-distance squared (GIDS). See pdf for article:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import HTML\n",
      "HTML('<iframe src=http://ibis.geog.ubc.ca/~ian/Comparison%20of%20approaches%20for%20spatial%20interpolation%20of%20daily%20air%20temperature%20in%20a%20large%20region%20with%20complex%20topography%20and%20highly%20variable%20station%20density.pdf width=700 height=350></iframe>')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<iframe src=http://ibis.geog.ubc.ca/~ian/Comparison%20of%20approaches%20for%20spatial%20interpolation%20of%20daily%20air%20temperature%20in%20a%20large%20region%20with%20complex%20topography%20and%20highly%20variable%20station%20density.pdf width=700 height=350></iframe>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "<IPython.core.display.HTML at 0x4517f60>"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As input I've (1) hourly climate variables of all weathers stations of China for June 2012, (2) locations of all stations in Aalbers projection and (3) the DEM of China with 1km resolution, also in Aalbers projection. From the climate variables available I use in this notebook only the air temperature."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This GIDS model selects 8 nearest neighbours for each coordinate (corresponding to a DEM pixel). Fits a multiple linear regression using the x, y and z as predictior variables and the desired variable as the dependent variable. Then apply a inverse-distance-squared weights to calculate the desired variable where the coefficients adjust each predictor variable. The model can be expressed as follows:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\\begin{equation*}DV_p =  \\sum_{i=1}^n (1/d_i)^2)^{-1} * \\sum_{i=1}^n((DV_i + b_1(Long_p - Long_i)+b_2(Lat_p-Lat_i)+b_3(h_p-h_i)) *(1/d_i)^2)\\end{equation*}"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Athmospheric data location\n",
      "filepath = r'D:\\TEMP\\GIDS_ZHOU\\CMA_201206'\n",
      "\n",
      "# Station data location\n",
      "filestations = r'D:\\TEMP\\GIDS_ZHOU\\AWS_stations_Aalbers.csv'\n",
      "\n",
      "# DEM location\n",
      "folderDEM = r'D:\\TEMP\\GIDS_ZHOU\\China_DEM//dem.tif'\n",
      "#folderMSK = r'E:\\Data\\WangKun@Mattijn\\DEM_MA01'\n",
      "\n",
      "# Out folder location\n",
      "outFolder = r'D:\\TEMP\\GIDS_ZHOU\\out_201206//'\n",
      "\n",
      "# Start and end date of the month\n",
      "start = '06/1/2012'\n",
      "end = '06/30/2012'\n",
      "\n",
      "# Parameter to interpolate and prefix to use\n",
      "param = 'TEMP'\n",
      "prefix = 't'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Import some modules that we are going to use"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy import stats\n",
      "from scipy.spatial.distance import cdist\n",
      "from scipy.spatial import cKDTree as KDTree\n",
      "import statsmodels.api as sm\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from osgeo import gdal\n",
      "import os\n",
      "import datetime\n",
      "from datetime import datetime\n",
      "\n",
      "# from __future__ import division # apply when using python2.7"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some defined functions to iterate files in folder and to open and save raster files"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def FilesFolder(inGSODFolder, format_end=''):\n",
      "    \"\"\"\n",
      "    Iterate through folder to find files.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    inGSODFolder : folder\n",
      "        folder to use for iteration.\n",
      "    format_end : string\n",
      "        Similar use as wildmark.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    st_wmo : list\n",
      "        list with files in folder specified by wildmark\n",
      "\n",
      "    \"\"\"    \n",
      "    st_wmo = [os.path.join(root, name)\n",
      "               for root, dirs, files in os.walk(inGSODFolder)\n",
      "                 for name in files                 \n",
      "                 if name.endswith(format_end)]\n",
      "    return st_wmo"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def OpenRaster(fileDEM):\n",
      "    \"\"\"\n",
      "    Read and opens array of first band of raster image.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    fileDEM : string\n",
      "        path to raster file.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    raster : list\n",
      "        metadata for raster file (x/y and CRI)\n",
      "    dem : ndarray\n",
      "        ndarray of the raster file\n",
      "    extent: ndarray\n",
      "        extent of the raster file\n",
      "\n",
      "    \"\"\"     \n",
      "    raster = gdal.Open(fileDEM, gdal.GA_ReadOnly)\n",
      "    band = raster.GetRasterBand(1)\n",
      "    dem = band.ReadAsArray()\n",
      "    extent = raster.GetGeoTransform()\n",
      "    return raster, dem, extent"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def saveRaster(path, array, raster, datatype=3, formatraster=\"GTiff\"): # float32 = 6, signed int = 3\n",
      "    \"\"\"\n",
      "    Save ndarray to specified format using GDAL\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    path : string\n",
      "        path to output.\n",
      "    array : ndarray\n",
      "        ndarray to write\n",
      "    raster: raster datasource \n",
      "        metadata for x/y and CRI\n",
      "    datatype: int\n",
      "        which datatype to store (6 = float 32, 3 = signed int)\n",
      "        default = 3\n",
      "    formatraster: string\n",
      "        specify the format to output\n",
      "        default = geotiff\n",
      "\n",
      "    \"\"\"      \n",
      "    # Set Driver\n",
      "    format_ = formatraster #save as format\n",
      "    driver = gdal.GetDriverByName( format_ )\n",
      "    driver.Register()\n",
      "    \n",
      "    # Set Metadata for Raster output\n",
      "    cols = raster.RasterXSize\n",
      "    rows = raster.RasterYSize\n",
      "    bands = raster.RasterCount\n",
      "    datatype = 6#band.DataType\n",
      "    \n",
      "    # Set Projection for Raster\n",
      "    outDataset = driver.Create(path, cols, rows, bands, datatype)\n",
      "    geoTransform = raster.GetGeoTransform()\n",
      "    outDataset.SetGeoTransform(geoTransform)\n",
      "    proj = raster.GetProjection()\n",
      "    outDataset.SetProjection(proj)\n",
      "    \n",
      "    # Write output to band 1 of new Raster\n",
      "    outBand = outDataset.GetRasterBand(1)\n",
      "    outBand.WriteArray(array) #save input array\n",
      "    #outBand.WriteArray(dem)\n",
      "    \n",
      "    # Close and finalise newly created Raster\n",
      "    #F_M01 = None\n",
      "    outBand = None\n",
      "    proj = None\n",
      "    geoTransform = None\n",
      "    outDataset = None\n",
      "    driver = None\n",
      "    datatype = None\n",
      "    bands = None\n",
      "    rows = None\n",
      "    cols = None\n",
      "    driver = None\n",
      "    array = None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The following function compute the [Cartesian product](http://www.wikiwand.com/en/Cartesian_product). I use this to create an array with all coordinates in Aalbers projection of all pixels in DEM file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def cartesian(arrays, out=None):\n",
      "    \"\"\"\n",
      "    Generate a cartesian product of input arrays.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    arrays : list of array-like\n",
      "        1-D arrays to form the cartesian product of.\n",
      "    out : ndarray\n",
      "        Array to place the cartesian product in.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        2-D array of shape (M, len(arrays)) containing cartesian products\n",
      "        formed of input arrays.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> cartesian(([1, 2, 3], [4, 5], [6, 7]))\n",
      "    array([[1, 4, 6],\n",
      "           [1, 4, 7],\n",
      "           [1, 5, 6],\n",
      "           [1, 5, 7],\n",
      "           [2, 4, 6],\n",
      "           [2, 4, 7],\n",
      "           [2, 5, 6],\n",
      "           [2, 5, 7],\n",
      "           [3, 4, 6],\n",
      "           [3, 4, 7],\n",
      "           [3, 5, 6],\n",
      "           [3, 5, 7]])\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "    arrays = [np.asarray(x) for x in arrays]\n",
      "    dtype = arrays[0].dtype\n",
      "\n",
      "    n = np.prod([x.size for x in arrays])\n",
      "    if out is None:\n",
      "        out = np.zeros([n, len(arrays)], dtype=dtype)\n",
      "\n",
      "    m = n / arrays[0].size\n",
      "    out[:,0] = np.repeat(arrays[0], m)\n",
      "    if arrays[1:]:\n",
      "        cartesian(arrays[1:], out=out[0:m,1:])\n",
      "        for j in range(1, arrays[0].size):\n",
      "            out[j*m:(j+1)*m,1:] = out[0:m,1:]\n",
      "    return out"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I've loaded the modules and defined some functions to use, now let's start with loading the CMA meteorological data file and make a range of available dates in the month of interest."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# select meteorological data file\n",
      "file_ = FilesFolder(filepath, format_end='.TXT')\n",
      "f = file_[0]\n",
      "print (f)\n",
      "\n",
      "# create range of dates\n",
      "rng = pd.date_range(start, end, freq='1D')\n",
      "print (rng)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "D:\\TEMP\\GIDS_ZHOU\\CMA_201206\\SURF_CLI_CHN_MUL_FTM-201206.TXT\n",
        "<class 'pandas.tseries.index.DatetimeIndex'>\n",
        "[2012-06-01, ..., 2012-06-30]\n",
        "Length: 30, Freq: D, Timezone: None\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next read the file into a pandas dataframe, set the datetime as index, select only the column of interest (TEMP in this case). As the values are hourly, let pandas resample to daily values."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# read file and parse the dates correctly\n",
      "df = pd.read_csv(f, sep='\\t', header=None,  \n",
      "                 parse_dates={'datetime': [1,2,3,4]}, \n",
      "                 date_parser=lambda x: pd.datetime.strptime(x, '%Y %m %d %H'))\n",
      "\n",
      "# set name of columns\n",
      "columns_df = ['datetime','Station','STP','a','TEMP','b','c','d','REHU','e','f','g','PRCP','h','i','WDSP','j','k','l','m','n','o', \\\n",
      "              'p','q','r','s','t']\n",
      "df.columns = columns_df\n",
      "\n",
      "# set date-time as index and select the variables needed\n",
      "df.set_index('datetime', inplace=True)\n",
      "df_sel = df[['Station', 'TEMP']]#'STP','TEMP','REHU','PRCP','WDSP']]\n",
      "\n",
      "# replace missing, blank and values for snow as NaN (based on metadata available)\n",
      "df_sel.replace(32766, np.nan, inplace=True)\n",
      "df_sel.replace(32744, np.nan, inplace=True)\n",
      "df_sel.replace(32700, np.nan, inplace=True)\n",
      "\n",
      "# make appropriate conversions to right unit (based on metadata available)\n",
      "#df_sel.STP *= 0.1\n",
      "df_sel.TEMP *= 10\n",
      "#df_sel.PRCP *= 0.1\n",
      "#df_sel.STP *= 0.1\n",
      "\n",
      "# group by Station ID and resample to daily values\n",
      "df_selDay = df_sel.groupby('Station').resample('1D')\n",
      "df_selDay = df_selDay.reset_index()\n",
      "df_selDay = df_selDay.set_index('datetime')\n",
      "\n",
      "print (df_selDay.head()) # shows the first five values of the table\n",
      "print ('\\n',df_selDay.max()) # print the maximum value of all stations"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "            Station         TEMP\n",
        "datetime                        \n",
        "2012-06-01    50136  1388.750000\n",
        "2012-06-02    50136  1571.666667\n",
        "2012-06-03    50136  1571.250000\n",
        "2012-06-04    50136  1461.250000\n",
        "2012-06-05    50136  1673.750000\n",
        "\n",
        " Station    59985.00\n",
        "TEMP        3681.25\n",
        "dtype: float64\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# read DEM\n",
      "raster, dem, extent = OpenRaster(folderDEM)\n",
      "\n",
      "# Get some metadata from the raster file\n",
      "band = raster.GetRasterBand(1)\n",
      "proj = raster.GetProjection()\n",
      "\n",
      "cols = raster.RasterXSize\n",
      "rows = raster.RasterYSize\n",
      "\n",
      "# read station locations \n",
      "df_stations = pd.read_csv(filestations)  \n",
      "\n",
      "print (proj, '\\n Numer of columns',cols, '\\n Number of rows',rows)\n",
      "print ('\\n',df_stations.head())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "PROJCS[\"IMAGINE GeoTIFF Support\n",
        "ERDAS IMAGINE 9.3 Service Pack 1 GeoTIFF support\n",
        "Projection = Albers Conical Equal Area\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Albers_Conic_Equal_Area\"],PARAMETER[\"standard_parallel_1\",15],PARAMETER[\"standard_parallel_2\",55],PARAMETER[\"latitude_of_center\",35],PARAMETER[\"longitude_of_center\",100],PARAMETER[\"false_easting\",4000000],PARAMETER[\"false_northing\",1000000],UNIT[\"meters\",1]] \n",
        " Numer of columns 4600 \n",
        " Number of rows 4300\n",
        "\n",
        "    Station   Elev      Long_x      Lat_y      POINT_X      POINT_Y\n",
        "0    50136  433.0  122.309997  52.580001  5473928.503  3209653.795\n",
        "1    50246  361.9  124.430000  52.209999  5621191.187  3199563.174\n",
        "2    50349  494.6  124.199996  51.419998  5626513.511  3108424.145\n",
        "3    50353  177.4  126.389999  51.430000  5770514.642  3144551.515\n",
        "4    50425  581.4  120.110000  50.150001  5382630.523  2908127.877\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Calculate the x and y steps in Aalbers projection to apply a Cartesian product"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_steps = np.arange(dem.shape[1]) * extent[1]\n",
      "y_steps = np.arange(dem.shape[0]) * extent[-1]        \n",
      "x_coords = extent[0] + x_steps + extent[1]/2\n",
      "y_coords = extent[3] + y_steps + extent[-1]/2\n",
      "\n",
      "xy = cartesian([x_coords, y_coords])\n",
      "\n",
      "dem = dem.T\n",
      "dem_rshp = dem.reshape(-1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def GIDS_UPDATE(xy_coord):\n",
      "    # Apply a KDTree search to select 8 nearest stations\n",
      "    dist_tree_real, ix_tree_real = tree.query(xy_coord, k=8, eps=0, p=1)\n",
      "    #print(dist_tree_real)\n",
      "    df_sel = df.ix[ix_tree_real]\n",
      "    #print(df_sel)\n",
      "    M = np.vstack((np.ones(len(df_sel['POINT_X'])),df_sel['POINT_X'], df_sel['POINT_Y'],df_sel['Elev'])).T\n",
      "    b1,b2,b3 = np.linalg.lstsq(M,df_sel['TEMP'])[0][1:4]\n",
      "    #print(b1,b2,b3)\n",
      "    return sum( (1/dist_tree_real)**2)**-1 * sum((df_sel['TEMP'] + (b1*(xy_coord[0] - df_sel['POINT_X'])) + \n",
      "                                                  (b2*(xy_coord[1]-df_sel['POINT_Y'])) + (b3*(dem[y,x]-df_sel['Elev']))) * \n",
      "                                                 (1/dist_tree_real)**2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# select meteorological data file\n",
      "file_ = FILES(filepath)\n",
      "f = file_[0]\n",
      "print (f)\n",
      "\n",
      "# create range of dates\n",
      "rng = pd.date_range(start, end, freq='D')\n",
      "print (rng)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# read file and parse the dates correctly\n",
      "df = pd.read_csv(f, sep='\\t', header=None,  \n",
      "                 parse_dates={'datetime': [1,2,3,4]}, \n",
      "                 date_parser=lambda x: pd.datetime.strptime(x, '%Y %m %d %H'))\n",
      "\n",
      "# set name of columns\n",
      "columns_df = ['datetime','Station','STP','a','TEMP','b','c','d','REHU','e','f','g','PRCP','h','i','WDSP','j','k','l','m','n','o', \\\n",
      "              'p','q','r','s','t']\n",
      "df.columns = columns_df\n",
      "\n",
      "# set date-time as index and select the variables needed\n",
      "df.set_index('datetime', inplace=True)\n",
      "df_sel = df[['Station', param]]#'STP','TEMP','REHU','PRCP','WDSP']]\n",
      "\n",
      "# replace missing, blank and values for snow as NaN\n",
      "df_sel.replace(32766, np.nan, inplace=True)\n",
      "df_sel.replace(32744, np.nan, inplace=True)\n",
      "df_sel.replace(32700, np.nan, inplace=True)\n",
      "\n",
      "# make appropriate concersions to right unit\n",
      "#df_sel.STP *= 0.1\n",
      "df_sel.TEMP *= 10\n",
      "#df_sel.PRCP *= 0.1\n",
      "#df_sel.STP *= 0.1\n",
      "\n",
      "# group by Station ID and resample to daily values\n",
      "df_selDay = df_sel.groupby('Station').resample('1D', how='mean')\n",
      "df_selDay = df_selDay.drop('Station',1)\n",
      "df_selDay = df_selDay.reset_index()\n",
      "df_selDay = df_selDay.set_index('datetime')\n",
      "print (df_selDay.head())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rsters = DEMfiles(folderDEM)\n",
      "df_stations = pd.read_csv(filestations)\n",
      "\n",
      "max_base = 0\n",
      "for rster in rsters:    \n",
      "    if len(rster) > max_base:\n",
      "        max_base = len(rster)\n",
      "        \n",
      "for rster in rsters:\n",
      "    print ('rster',rster)\n",
      "    raster, dem, extent = inRaster(rster)\n",
      "    \n",
      "    x_steps = np.arange(dem.shape[1]) * extent[1]\n",
      "    y_steps = np.arange(dem.shape[0]) * extent[-1]        \n",
      "    x_coords = extent[0] + x_steps + extent[1]/2\n",
      "    y_coords = extent[3] + y_steps + extent[-1]/2        \n",
      "    xy = cartesian([x_coords, y_coords])\n",
      "    dem = dem.T\n",
      "    dem_rshp = dem.reshape(-1)\n",
      "    #print ('extent\\n', extent)\n",
      "    #print ('raster_description\\n', raster.GetDescription())\n",
      "    #print ('xy\\n',xy,'\\ndem\\n', dem)\n",
      "    #print ('dem.shape\\n', dem.shape)\n",
      "\n",
      "    for i in rng:     \n",
      "        #i = rng\n",
      "        #print ('\\ndate of range\\n', i)\n",
      "        data_left = df_selDay.ix[i]    \n",
      "        sel_merge = pd.merge(data_left, df_stations, on='Station', how='inner', )\n",
      "        #print ('\\nInner merge on station and data frame\\n', sel_merge.head())\n",
      "                \n",
      "        #TEMP\n",
      "        df = sel_merge[pd.notnull(sel_merge['TEMP'])]\n",
      "        df.reset_index(drop=True, inplace=True)        \n",
      "        #print ('\\nDrop not null and reset index\\n', df.head())\n",
      "        \n",
      "        tree = KDTree(df.ix[:,5:7], leafsize=11)\n",
      "        #print ('stations\\n',df.head(),'\\ntimestamp\\n',i)\n",
      "        \n",
      "        dist, idx = tree.query(xy, k=8, eps=0, p=1)        \n",
      "        columns = [\"POINT_X\", \"POINT_Y\", \"Elev\", \"TEMP\"]\n",
      "        px, py, elev, tmp = df[columns].values.T[:, idx, None]\n",
      "        #print ('px\\n',px,'\\npy\\n', py, '\\nelev\\n' ,elev, '\\ntmp\\n', tmp)\n",
      "        \n",
      "        tmp = np.squeeze(tmp)\n",
      "        one = np.ones_like(px)\n",
      "        \n",
      "        m = np.concatenate((one,px,py,elev), axis =-1)\n",
      "        mtm = np.einsum(\"ijx,ijy->ixy\", m, m)\n",
      "        mty = np.einsum(\"ijx,ij->ix\", m, tmp)\n",
      "        b1,b2,b3 = np.linalg.solve(mtm, mty)[:, 1:].T        \n",
      "        \n",
      "        px, py, elev = px.squeeze(), py.squeeze(), elev.squeeze()\n",
      "        \n",
      "        b1 = b1[:,None]\n",
      "        b2 = b2[:,None]\n",
      "        b3 = b3[:,None]\n",
      "        #print ('b1\\n',b1,'\\nb2\\n',b2, '\\nb3\\n',b3)\n",
      "        \n",
      "        rdist = (1/dist)**2\n",
      "        t0 = tmp + b1*(xy[:,0,None]-px) + b2*(xy[:,1,None]-py) + b3*(dem_rshp[:,None]-elev)\n",
      "        outarr = (t0*rdist).sum(1) / rdist.sum(1)\n",
      "        \n",
      "        outArray = outarr.reshape([dem.shape[0],dem.shape[1]]).T\n",
      "        #print ('outArray\\n',outArray)\n",
      "        #print ('outArray.shape\\n',outArray.shape)\n",
      "    \n",
      "        #save output as raster\n",
      "        if len(raster.GetDescription()) == max_base: # fixed code to check the length of the path\n",
      "            add = raster.GetDescription()[-6:-4]\n",
      "        else:\n",
      "            add = raster.GetDescription()[-5:-4]\n",
      "            \n",
      "        date = str(i.year)+str(i.month).zfill(2)+str(i.day).zfill(2)\n",
      "        outFilename = outFolder+prefix+str(date)+'_'+str(add.zfill(2))+'.tif'\n",
      "        #print (outFilename)\n",
      "        \n",
      "        saveRaster(outFilename, outArray)\n",
      "        outFilename = None  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in rng:     \n",
      "    #print ('\\ndate of range\\n', i)\n",
      "    data_left = df_selDay.ix[i]    \n",
      "    sel_merge = pd.merge(data_left, df_stations, on='Station', how='inner', )\n",
      "    #print ('\\nInner merge on station and data frame\\n', sel_merge.head())\n",
      "        \n",
      "    #TEMP\n",
      "    df = sel_merge[pd.notnull(sel_merge['TEMP'])]\n",
      "    df.reset_index(drop=True, inplace=True)        \n",
      "    #print ('\\nDrop not null and reset index\\n', df.head())\n",
      "\n",
      "    tree = KDTree(df.ix[:,5:7], leafsize=11)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rsters = DEMfiles(folderDEM)\n",
      "masks = DEMfiles(folderMSK)\n",
      "\n",
      "max_base = 0\n",
      "for rster in rsters:    \n",
      "    if len(rster) > max_base:\n",
      "        max_base = len(rster)\n",
      "max_one = max_base - 1\n",
      "max_two = max_base - 2\n",
      "\n",
      "df_stations = pd.read_csv(filestations)\n",
      "\n",
      "for rster in rsters:    \n",
      "    raster, dem, extent = inRaster(rster)    \n",
      "    for mask in masks:\n",
      "        if len(rster) == max_base and len(mask)==max_one:\n",
      "            if int(mask[-6:-4]) == int(rster[-6:-4]):\n",
      "                mskpth = mask                \n",
      "        elif len(rster) == max_one and len(mask)==max_two:\n",
      "            if int(mask[-5:-4]) == int(rster[-5:-4]):\n",
      "                mskpth = mask\n",
      "    mask_raster, mask_dem, mask_extent = inRaster(mskpth)\n",
      "    #print (raster.GetDescription())\n",
      "    #print (mask_raster.GetDescription())   \n",
      "    dem = dem.reshape(-1)\n",
      "    for i in rng:     \n",
      "        #print ('\\ndate of range\\n', i)\n",
      "        data_left = df_selDay.ix[i]    \n",
      "        sel_merge = pd.merge(data_left, df_stations, on='Station', how='inner', )\n",
      "        #print ('\\nInner merge on station and data frame\\n', sel_merge.head())\n",
      "        \n",
      "        #TEMP\n",
      "        df = sel_merge[pd.notnull(sel_merge['TEMP'])]\n",
      "        df.reset_index(drop=True, inplace=True)        \n",
      "        #print ('\\nDrop not null and reset index\\n', df.head())\n",
      "\n",
      "        tree = KDTree(df.ix[:,5:7], leafsize=11)\n",
      "\n",
      "        x_steps = np.arange(dem.shape[1]) * extent[1]\n",
      "        y_steps = np.arange(dem.shape[0]) * extent[-1]\n",
      "        \n",
      "        x_coords = extent[0] + x_steps + extent[1]/2\n",
      "        y_coords = extent[3] + y_steps + extent[-1]/2\n",
      "        #print('\\nX and Y coords\\n', x_coords,y_coords)\n",
      "        \n",
      "        cart = cartesian([x_coords, y_coords])\n",
      "        cart_array = cart.reshape((dem.shape[1],dem.shape[0],2))\n",
      "        \n",
      "        tp = np.zeros([dem.shape[1],dem.shape[0]])\n",
      "        #x=25\n",
      "        #y=75\n",
      "        #print ('\\nCoordinates to examine\\n', cart_array[x,y,0:2])\n",
      "        #print ('\\nDEM value\\n', dem[y,x])\n",
      "        #check = GIDS_UPDATE(cart_array[x,y,0:2])\n",
      "        #print (check)\n",
      "        \n",
      "        for x in range(dem.shape[1]):\n",
      "            for y in range(dem.shape[0]):\n",
      "                #print x, y, m_dem[y,x]\n",
      "                if mask_dem[y,x] == 1:\n",
      "                    tp[x][y] = GIDS_UPDATE(cart_array[x,y,0:2])\n",
      "                else:\n",
      "                    tp[x][y] = 32766                 \n",
      "\n",
      "        tp = tp.T\n",
      "        \n",
      "        #save output as raster\n",
      "        if len(raster.GetDescription()) == max_base: # fixed code to check the length of the path\n",
      "            add = raster.GetDescription()[-6:-4]\n",
      "        else:\n",
      "            add = raster.GetDescription()[-5:-4]\n",
      "            \n",
      "        date = str(i.year)+str(i.month).zfill(2)+str(i.day).zfill(2)\n",
      "        outFilename = outFolder+prefix+str(date)+'_'+str(add.zfill(2))+'.tif'\n",
      "        print (outFilename)\n",
      "        \n",
      "        saveRaster(outFilename, tp)\n",
      "        outFilename = None\n",
      "        tp = None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}