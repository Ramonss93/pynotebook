{
 "metadata": {
  "name": "From Raster to GeoSOM"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Demonstration of my code developed so far to prepare multiple remote sensing time series for kohonen network analysis.\n",
      "\n",
      "First import libraries"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import pandas as pd\n",
      "from pandas import HDFStore\n",
      "import gdal\n",
      "import osr\n",
      "import matplotlib.pyplot as plt\n",
      "from mpl_toolkits.basemap import Basemap\n",
      "import numpy as np\n",
      "import numpy.ma as ma\n",
      "import decimal\n",
      "import subprocess as sp\n",
      "import numexpr\n",
      "import bottleneck\n",
      "import time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "List of all strings used in code"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "NR_Files = r'I:/Data/3Params/AIRTEMP'\n",
      "ET_Files = r'I:/Data/3Params/MODIS16NA'\n",
      "P_Files = r'I:/Data/3Params/TRMM3B43'\n",
      "maskRastr = r'I:\\Data\\3Params\\LC\\ProjectArea.tif'\n",
      "outpFiles = r'I:\\Data\\3Params\\OUTPUT/'\n",
      "somSource = r'C:/Program Files/SOMToolbox/somtoolbox.bat'\n",
      "fromMask = int(0)\n",
      "toMask = int(17)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "NR_Files"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 67,
       "text": [
        "'I:/Data/3Params/AIRTEMP'"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Function to create lists of all raster inputs as Strings.\n",
      "Search subfolders to create List of input"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def rasterList(varpath, endwith, namefile):\n",
      "    # 1 - Precipitation\n",
      "    input_folder = varpath\n",
      "    varList = [os.path.join(root, name)\n",
      "                 for root, dirs, files in os.walk(input_folder)\n",
      "                 for name in files\n",
      "                 if name.endswith((endwith))]\n",
      "    print namefile + \" files : \"  + str(len(varList))\n",
      "    return varList"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 68
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "For each variable create a list with the input raster files.\n",
      "Print one list for checking purposes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "NRList = rasterList(NR_Files, \".tif\", \"NR\")\n",
      "ETList = rasterList(ET_Files, \".tif\", \"ET\")\n",
      "PList = rasterList(P_Files, \".tif\", \"P\")\n",
      "\n",
      "print NRList"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "NR files : 46\n",
        "ET files : 46"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "P files : 46\n",
        "['I:/Data/3Params/AIRTEMP\\\\2009001.tif', 'I:/Data/3Params/AIRTEMP\\\\2009009.tif', 'I:/Data/3Params/AIRTEMP\\\\2009017.tif', 'I:/Data/3Params/AIRTEMP\\\\2009025.tif', 'I:/Data/3Params/AIRTEMP\\\\2009033.tif', 'I:/Data/3Params/AIRTEMP\\\\2009041.tif', 'I:/Data/3Params/AIRTEMP\\\\2009049.tif', 'I:/Data/3Params/AIRTEMP\\\\2009057.tif', 'I:/Data/3Params/AIRTEMP\\\\2009065.tif', 'I:/Data/3Params/AIRTEMP\\\\2009073.tif', 'I:/Data/3Params/AIRTEMP\\\\2009081.tif', 'I:/Data/3Params/AIRTEMP\\\\2009089.tif', 'I:/Data/3Params/AIRTEMP\\\\2009097.tif', 'I:/Data/3Params/AIRTEMP\\\\2009105.tif', 'I:/Data/3Params/AIRTEMP\\\\2009113.tif', 'I:/Data/3Params/AIRTEMP\\\\2009121.tif', 'I:/Data/3Params/AIRTEMP\\\\2009129.tif', 'I:/Data/3Params/AIRTEMP\\\\2009137.tif', 'I:/Data/3Params/AIRTEMP\\\\2009145.tif', 'I:/Data/3Params/AIRTEMP\\\\2009153.tif', 'I:/Data/3Params/AIRTEMP\\\\2009161.tif', 'I:/Data/3Params/AIRTEMP\\\\2009169.tif', 'I:/Data/3Params/AIRTEMP\\\\2009177.tif', 'I:/Data/3Params/AIRTEMP\\\\2009185.tif', 'I:/Data/3Params/AIRTEMP\\\\2009193.tif', 'I:/Data/3Params/AIRTEMP\\\\2009201.tif', 'I:/Data/3Params/AIRTEMP\\\\2009209.tif', 'I:/Data/3Params/AIRTEMP\\\\2009217.tif', 'I:/Data/3Params/AIRTEMP\\\\2009225.tif', 'I:/Data/3Params/AIRTEMP\\\\2009233.tif', 'I:/Data/3Params/AIRTEMP\\\\2009241.tif', 'I:/Data/3Params/AIRTEMP\\\\2009249.tif', 'I:/Data/3Params/AIRTEMP\\\\2009257.tif', 'I:/Data/3Params/AIRTEMP\\\\2009265.tif', 'I:/Data/3Params/AIRTEMP\\\\2009273.tif', 'I:/Data/3Params/AIRTEMP\\\\2009281.tif', 'I:/Data/3Params/AIRTEMP\\\\2009289.tif', 'I:/Data/3Params/AIRTEMP\\\\2009297.tif', 'I:/Data/3Params/AIRTEMP\\\\2009305.tif', 'I:/Data/3Params/AIRTEMP\\\\2009313.tif', 'I:/Data/3Params/AIRTEMP\\\\2009321.tif', 'I:/Data/3Params/AIRTEMP\\\\2009329.tif', 'I:/Data/3Params/AIRTEMP\\\\2009337.tif', 'I:/Data/3Params/AIRTEMP\\\\2009345.tif', 'I:/Data/3Params/AIRTEMP\\\\2009353.tif', 'I:/Data/3Params/AIRTEMP\\\\2009361.tif']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Function to open raster image by providing filepath used to define the \n",
      "subsets for the grouping of variables"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def SubsetImg(nameras):\n",
      "    # Open landcover image\n",
      "    a = gdal.Open(nameras, gdal.GA_ReadOnly)\n",
      "    b = a.GetRasterBand(1)\n",
      "    InRas = b.ReadAsArray()\n",
      "    return InRas"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Define a function that can visualise the output of the selected parts\n",
      "of the landcover map by using basemap library."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_gdal_file ( input_dataset, x, vmin=0, vmax=100 ):\n",
      "    # Need to get the geotransform (ie, corners)\n",
      "    geo = input_dataset.GetGeoTransform()\n",
      "    data = x\n",
      "\n",
      "    # We need to flip the raster upside down\n",
      "    data = np.flipud( data )\n",
      "\n",
      "    # Define a cylindrical projection\n",
      "    projection_opts={'projection':'cyl','resolution':'h'}\n",
      "\n",
      "    # These are the extents in the native raster coordinates\n",
      "    extent = [ geo[0],  geo[0] + input_dataset.RasterXSize*geo[1], \\\n",
      "        geo[3], geo[3] + input_dataset.RasterYSize*geo[5]]\n",
      "    map = Basemap( llcrnrlon=extent[0], llcrnrlat=extent[3], \\\n",
      "                 urcrnrlon=extent[1],urcrnrlat=extent[2],  ** projection_opts)\n",
      "\n",
      "    # Set up some variables of the map presentation\n",
      "    cmap = plt.cm.gist_rainbow\n",
      "    cmap.set_under ('0.8' )\n",
      "    cmap.set_bad('0.8' )\n",
      "    cmap.set_over ('0.8')\n",
      "\n",
      "    # Set range colourbar, draw country borders\n",
      "    map.imshow( data, vmin=vmin, vmax=vmax, cmap=cmap, interpolation='nearest')\n",
      "    map.drawcoastlines (linewidth=0.5, color='k')\n",
      "    map.drawcountries(linewidth=0.5, color='k')\n",
      "    map.drawmeridians( np.arange(0,360,5), color='k')\n",
      "    map.drawparallels( np.arange(-90,90,5), color='k')\n",
      "    map.drawmapboundary()\n",
      "\n",
      "    cb = plt.colorbar( orientation='horizontal', fraction=0.10, shrink=0.8)\n",
      "\n",
      "    # Add custom title to map\n",
      "    plt.title('Landcovertype '+str(i)+' (subset contains: '+str(z)+' values)')\n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Load the landcover raster map and create raster file with shape of Landcover\n",
      "raster map to be able to plot the subsets. Further plot original image."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nameras = maskRastr\n",
      "InRas = SubsetImg(nameras)\n",
      "a = gdal.Open(nameras, gdal.GA_ReadOnly)\n",
      "x = np.empty(InRas.shape); x[:] = 127\n",
      "i = '0 - 16'\n",
      "z = InRas.shape[0]*InRas.shape[1]\n",
      "#plot_gdal_file(a,InRas,vmin=0,vmax=17) # Return landcover dataset"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Function raster2hdf: input listvar = list: name of raster for the\n",
      "specific variable, namevar = 'string': name of column for HDF5 table"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def raster2hdf(listvar, namevar):\n",
      "    for raster in listvar:\n",
      "\n",
      "        c = gdal.Open(raster, gdal.GA_ReadOnly)\n",
      "        d = c.GetRasterBand(1)\n",
      "        r_data = d.ReadAsArray()\n",
      "        root, ext = os.path.splitext(raster)\n",
      "        name = int(decimal.Decimal(os.path.basename(root)))\n",
      "\n",
      "        # Extract real values from array by compressing the masked items\n",
      "        # Convert numpy array to DataFrame and append to HDF5 table\n",
      "        Arr_df = pd.DataFrame(dict(x=indices[0],\n",
      "                                   y=indices[1],\n",
      "                                   date=name,\n",
      "                                   value=r_data[indices].astype('float'))\n",
      "                              ).set_index(['x','y','date'])\n",
      "        Arr_df.rename(index=None, columns={'value':namevar}, inplace=True)\n",
      "        store.append(namevar,Arr_df)\n",
      "\n",
      "        # Clean up my dirt\n",
      "        c = None\n",
      "        d = None\n",
      "        r_data = None\n",
      "        Arr_extr = None\n",
      "        Arr_df = None\n",
      "        Arr_x = None\n",
      "        Arr_y = None\n",
      "\n",
      "    return store"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Iterate over the different landcover types and extract the area of the\n",
      "Different remote sensing products equal to the landcover type. Store both\n",
      "values as indices in HDFStore."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(fromMask,toMask):\n",
      "    # Create HDF5 store files\n",
      "    outFile =outpFiles+str(i)+'.h5'\n",
      "    print outFile\n",
      "    store = HDFStore(outFile, mode='a')\n",
      "\n",
      "    # Mask everything what is not equal to the current landcover type\n",
      "    # Return number of elements of unmasked items for dimensions numpy array\n",
      "    indices = np.where(InRas==i)\n",
      "\n",
      "    x[indices] = i\n",
      "    z = np.sum(x==i)\n",
      "    #plot_gdal_file(a,x,vmin=0,vmax=17) # Return plot to visualise mask\n",
      "    x[:] = 127\n",
      "\n",
      "    # 1 - NR\n",
      "    print \"NR........................... OK\"\n",
      "    raster2hdf(NRList,'NR')\n",
      "    # 2 - ET\n",
      "    print \"ET........................... OK\"\n",
      "    raster2hdf(ETList,'ET')\n",
      "    # 3 - P\n",
      "    print \"P............................ OK\"\n",
      "    raster2hdf(PList,'P')    \n",
      "    print store"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Next few lines of code returns the head of the different nodes saved in the\n",
      "HDFStore"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print store['NR'].head(2)\n",
      "print store['ET'].head(2)\n",
      "print store['P'].head(2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Now we've converted and appended the data of the remote sensing products into\n",
      "Different HDFStores. But next step is to do an inner merge on the data values\n",
      "to obtain a new node to be used as input for the kohonen analysis. Let's\n",
      "start with creating a list of the .h5 files in the folder used for conversion."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hdfList = rasterList(outpFiles, '.h5','HDFStore')\n",
      "A = store"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'store' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-70-ea5f033d2a88>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mhdfList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrasterList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutpFiles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'.h5'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'HDFStore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstore\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mNameError\u001b[0m: name 'store' is not defined"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "HDFStore files : 23\n"
       ]
      }
     ],
     "prompt_number": 70
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "We will only demonstrate the code for the file instead of using a for loop.\n",
      "Firstly create a link to the store containing the data and create a\n",
      "temporarily HDFStore."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hdfList[3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 71,
       "text": [
        "'I:\\\\Data\\\\3Params\\\\OUTPUT/10.h5'"
       ]
      }
     ],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#h5 = hdfList[2]\n",
      "#h5temp = h5.replace('.h5','temp.h5')\n",
      "#A = HDFStore(h5)\n",
      "#Atemp = HDFStore(h5temp)\n",
      "#print A\n",
      "#print Atemp\n",
      "A = HDFStore(hdfList[3])\n",
      "#print h5\n",
      "Atemp = HDFStore(hdfList[4])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 72
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Then we set the chunk size and get the number of rows of the two nodes to be\n",
      "able to decide the start and stop moments of each chunk"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nrows_a = A.get_storer('NR').nrows\n",
      "nrows_b = A.get_storer('ET').nrows\n",
      "a_chunk_size = 100000\n",
      "b_chunk_size = 100000"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Now we can merge the two nodes together with the following code. The merged\n",
      "nodes will be stored in the temporarily store Atemp."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for a in xrange(int(nrows_a / a_chunk_size) + 1):\n",
      "    a_start_i = a * a_chunk_size\n",
      "    a_stop_i  = min((a + 1) * a_chunk_size, nrows_a)\n",
      "    print '** NR rows '+str(a_start_i)+' - '+str(a_stop_i)+' **'\n",
      "    a = A.select('NR', start = a_start_i, stop = a_stop_i)\n",
      "    for b in xrange(int(nrows_b / b_chunk_size) + 1):\n",
      "        b_start_i = b * b_chunk_size\n",
      "        b_stop_i = min((b + 1) * b_chunk_size, nrows_b)\n",
      "        print 'ET rows '+str(b_start_i)+' - '+str(b_stop_i)\n",
      "        b = A.select('ET', start = b_start_i, stop = b_stop_i)\n",
      "        try:\n",
      "            df = pd.merge(a, b , left_index=True, right_index=True,how='inner')\n",
      "        except Exception as err:\n",
      "            print \"no merge possible between rows, but let's continue\"\n",
      "            df = []\n",
      "        if len(df):\n",
      "            Atemp.append('NE', df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Since we want to merge all the different remote sensing products set up a\n",
      "function which assist us."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def mergeVarAAtemp(col_in1,col_in2,col_out):\n",
      "    print 'merging '+col_in1+' with '+col_in2+' to '+col_out\n",
      "    nrows_a = A.get_storer(col_in1).nrows\n",
      "    nrows_b = Atemp.get_storer(col_in2).nrows\n",
      "    a_chunk_size = 100000\n",
      "    b_chunk_size = 100000\n",
      "\n",
      "    for a in xrange(int(nrows_a / a_chunk_size) + 1):\n",
      "        a_start_i = a * a_chunk_size\n",
      "        a_stop_i  = min((a + 1) * a_chunk_size, nrows_a)\n",
      "        print '* '+str(col_in1)+' rows '+str(a_start_i)+' - '+str(a_stop_i)+' *'\n",
      "        a = A.select(col_in1, start = a_start_i, stop = a_stop_i)\n",
      "        for b in xrange(int(nrows_b / b_chunk_size) + 1):\n",
      "            b_start_i = b * b_chunk_size\n",
      "            b_stop_i = min((b + 1) * b_chunk_size, nrows_b)\n",
      "            print str(col_in2)+' rows '+str(b_start_i)+' - '+str(b_stop_i)\n",
      "            b = Atemp.select(col_in2, start = b_start_i, stop = b_stop_i)\n",
      "            try:\n",
      "                df = pd.merge(a, b , left_index=True, right_index=True,\n",
      "                              how='inner')\n",
      "            except Exception as err:\n",
      "                print \"no merge possible between rows, but let's continue\"\n",
      "                ##df = pd.merge(a, b , left_index=True, right_index=True, how='outer').dropna()\n",
      "                df = []\n",
      "            if len(df):\n",
      "                Atemp.append(col_out, df)\n",
      "    return\n",
      "\n",
      "mergeVarAAtemp('P','NE','NEP')\n",
      "del Atemp['NE']\n",
      "print \"Merging data columns......... OK\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Add index and normalise"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from numpy import nan\n",
      "grp = Atemp.select('NEP', where = [ 'date=%s' % 2009009])\n",
      "a = grp.reset_index()\n",
      "del a['date']\n",
      "d = a['ET'].min()\n",
      "e = a.replace(d, NaN)\n",
      "f = e[np.isfinite(e['ET'])]\n",
      "out = r'I:\\Data\\3Params\\OUTPUT/2009009.csv'\n",
      "f.to_csv(out, sep=',', header=True, index=False, mode='ab') "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 123
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b = pd.DataFrame(pd.Series(xrange(1,a.shape[0]+1)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c = pd.concat([b,a], axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 90
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 93
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 110
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 111
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "e.head()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 114
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f\n",
      "out2 = r'I:\\Data\\3Params\\OUTPUT/2009001a.csv'\n",
      "\n",
      "f.to_csv(out2, sep=',', header=True, index=False, mode='ab') "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 120
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#for chunk in Atemp.select('NEP', chunksize=100\n",
      "groups = Atemp.unique('NEP','date')\n",
      "#print \"\\ngroups:%s\" % groups\n",
      "for g in groups:\n",
      "    print \"\\nsort by:%s ...\" % g\n",
      "    grp = Atemp.select('NEP', where = [ 'date=%s' % g])\n",
      "    \n",
      "    # Add right index by resetting and setting index\n",
      "    qa = grp.reset_index()\n",
      "    qa['data_column']= pd.DataFrame(pd.Series(xrange(1,grp.shape[0]+1)))\n",
      "    ba= qa.set_index(['x','y','date'])\n",
      "    \n",
      "    # Write Header to CSV file\n",
      "    outVec = hdfList[4].replace('10temp.h5',str(g)+'.vec') \n",
      "    a = np.asarray([['$TYPE vec'],\n",
      "                ['$XDIM '+str(ba.shape[0])],\n",
      "                ['$YDIM 1'],\n",
      "                ['$VEC_DIM 3']\n",
      "               ])\n",
      "    np.savetxt(outVec,a, fmt='%s')\n",
      "    \n",
      "    # Write Data to CSV File\n",
      "    ba.to_csv(outVec, sep=' ', header=False, index=False, mode='ab') \n",
      "    \n",
      "    # Normalisation of the data\n",
      "    outVecNorm = outVec.replace('.vec','_norm.vec')\n",
      "    bat = somSource\n",
      "    paramsnorm = [bat, \"SOMLibVectorNormalization\", \"-m\", \"STANDARD_SCORE\",\n",
      "              outVec, outVecNorm]\n",
      "    #print sp.list2cmdline(paramsnorm)\n",
      "    norm = sp.Popen(sp.list2cmdline(paramsnorm))\n",
      "print \"Data normalisation........... OK\"\n",
      "    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" SOMLibVectorNormalization -m STANDARD_SCORE I:\\Data\\3Params\\OUTPUT/2009001.vec I:\\Data\\3Params\\OUTPUT/2009001_norm.vec\n",
        "Data normalisation........... OK"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" SOMLibVectorNormalization -m STANDARD_SCORE I:\\Data\\3Params\\OUTPUT/2009009.vec I:\\Data\\3Params\\OUTPUT/2009009_norm.vec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Data normalisation........... OK\n",
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" SOMLibVectorNormalization -m STANDARD_SCORE I:\\Data\\3Params\\OUTPUT/2009017.vec I:\\Data\\3Params\\OUTPUT/2009017_norm.vec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Data normalisation........... OK\n",
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" SOMLibVectorNormalization -m STANDARD_SCORE I:\\Data\\3Params\\OUTPUT/2009025.vec I:\\Data\\3Params\\OUTPUT/2009025_norm.vec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Data normalisation........... OK\n",
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" SOMLibVectorNormalization -m STANDARD_SCORE I:\\Data\\3Params\\OUTPUT/2009033.vec I:\\Data\\3Params\\OUTPUT/2009033_norm.vec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Data normalisation........... OK\n",
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" SOMLibVectorNormalization -m STANDARD_SCORE I:\\Data\\3Params\\OUTPUT/2009041.vec I:\\Data\\3Params\\OUTPUT/2009041_norm.vec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Data normalisation........... OK\n",
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" SOMLibVectorNormalization -m STANDARD_SCORE I:\\Data\\3Params\\OUTPUT/2009049.vec I:\\Data\\3Params\\OUTPUT/2009049_norm.vec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Data normalisation........... OK\n",
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" SOMLibVectorNormalization -m STANDARD_SCORE I:\\Data\\3Params\\OUTPUT/2009057.vec I:\\Data\\3Params\\OUTPUT/2009057_norm.vec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Data normalisation........... OK\n",
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" SOMLibVectorNormalization -m STANDARD_SCORE I:\\Data\\3Params\\OUTPUT/2009065.vec I:\\Data\\3Params\\OUTPUT/2009065_norm.vec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Data normalisation........... OK\n",
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" SOMLibVectorNormalization -m STANDARD_SCORE I:\\Data\\3Params\\OUTPUT/2009073.vec I:\\Data\\3Params\\OUTPUT/2009073_norm.vec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Data normalisation........... OK\n",
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" SOMLibVectorNormalization -m STANDARD_SCORE I:\\Data\\3Params\\OUTPUT/2009081.vec I:\\Data\\3Params\\OUTPUT/2009081_norm.vec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Data normalisation........... OK\n",
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" SOMLibVectorNormalization -m STANDARD_SCORE I:\\Data\\3Params\\OUTPUT/2009089.vec I:\\Data\\3Params\\OUTPUT/2009089_norm.vec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Data normalisation........... OK\n",
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" SOMLibVectorNormalization -m STANDARD_SCORE I:\\Data\\3Params\\OUTPUT/2009097.vec I:\\Data\\3Params\\OUTPUT/2009097_norm.vec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Data normalisation........... OK\n",
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" SOMLibVectorNormalization -m STANDARD_SCORE I:\\Data\\3Params\\OUTPUT/2009105.vec I:\\Data\\3Params\\OUTPUT/2009105_norm.vec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Data normalisation........... OK\n",
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" SOMLibVectorNormalization -m STANDARD_SCORE I:\\Data\\3Params\\OUTPUT/2009113.vec I:\\Data\\3Params\\OUTPUT/2009113_norm.vec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Data normalisation........... OK\n",
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" SOMLibVectorNormalization -m STANDARD_SCORE I:\\Data\\3Params\\OUTPUT/2009121.vec I:\\Data\\3Params\\OUTPUT/2009121_norm.vec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Data normalisation........... OK\n",
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" SOMLibVectorNormalization -m STANDARD_SCORE I:\\Data\\3Params\\OUTPUT/2009129.vec I:\\Data\\3Params\\OUTPUT/2009129_norm.vec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Data normalisation........... OK\n",
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" SOMLibVectorNormalization -m STANDARD_SCORE I:\\Data\\3Params\\OUTPUT/2009137.vec I:\\Data\\3Params\\OUTPUT/2009137_norm.vec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Data normalisation........... OK\n",
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" SOMLibVectorNormalization -m STANDARD_SCORE I:\\Data\\3Params\\OUTPUT/2009145.vec I:\\Data\\3Params\\OUTPUT/2009145_norm.vec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Data normalisation........... OK\n",
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" SOMLibVectorNormalization -m STANDARD_SCORE I:\\Data\\3Params\\OUTPUT/2009153.vec I:\\Data\\3Params\\OUTPUT/2009153_norm.vec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Data normalisation........... OK\n",
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" SOMLibVectorNormalization -m STANDARD_SCORE I:\\Data\\3Params\\OUTPUT/2009161.vec I:\\Data\\3Params\\OUTPUT/2009161_norm.vec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Data normalisation........... OK\n",
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" SOMLibVectorNormalization -m STANDARD_SCORE I:\\Data\\3Params\\OUTPUT/2009169.vec I:\\Data\\3Params\\OUTPUT/2009169_norm.vec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Data normalisation........... OK\n",
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" SOMLibVectorNormalization -m STANDARD_SCORE I:\\Data\\3Params\\OUTPUT/2009177.vec I:\\Data\\3Params\\OUTPUT/2009177_norm.vec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Data normalisation........... OK\n",
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" SOMLibVectorNormalization -m STANDARD_SCORE I:\\Data\\3Params\\OUTPUT/2009185.vec I:\\Data\\3Params\\OUTPUT/2009185_norm.vec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Data normalisation........... OK\n",
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" SOMLibVectorNormalization -m STANDARD_SCORE I:\\Data\\3Params\\OUTPUT/2009193.vec I:\\Data\\3Params\\OUTPUT/2009193_norm.vec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Data normalisation........... OK\n",
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" SOMLibVectorNormalization -m STANDARD_SCORE I:\\Data\\3Params\\OUTPUT/2009201.vec I:\\Data\\3Params\\OUTPUT/2009201_norm.vec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Data normalisation........... OK\n",
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" SOMLibVectorNormalization -m STANDARD_SCORE I:\\Data\\3Params\\OUTPUT/2009209.vec I:\\Data\\3Params\\OUTPUT/2009209_norm.vec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Data normalisation........... OK\n",
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" SOMLibVectorNormalization -m STANDARD_SCORE I:\\Data\\3Params\\OUTPUT/2009217.vec I:\\Data\\3Params\\OUTPUT/2009217_norm.vec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Data normalisation........... OK\n",
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" SOMLibVectorNormalization -m STANDARD_SCORE I:\\Data\\3Params\\OUTPUT/2009225.vec I:\\Data\\3Params\\OUTPUT/2009225_norm.vec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Data normalisation........... OK\n",
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" SOMLibVectorNormalization -m STANDARD_SCORE I:\\Data\\3Params\\OUTPUT/2009233.vec I:\\Data\\3Params\\OUTPUT/2009233_norm.vec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Data normalisation........... OK\n",
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" SOMLibVectorNormalization -m STANDARD_SCORE I:\\Data\\3Params\\OUTPUT/2009241.vec I:\\Data\\3Params\\OUTPUT/2009241_norm.vec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Data normalisation........... OK\n",
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" SOMLibVectorNormalization -m STANDARD_SCORE I:\\Data\\3Params\\OUTPUT/2009249.vec I:\\Data\\3Params\\OUTPUT/2009249_norm.vec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Data normalisation........... OK\n",
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" SOMLibVectorNormalization -m STANDARD_SCORE I:\\Data\\3Params\\OUTPUT/2009257.vec I:\\Data\\3Params\\OUTPUT/2009257_norm.vec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Data normalisation........... OK\n",
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" SOMLibVectorNormalization -m STANDARD_SCORE I:\\Data\\3Params\\OUTPUT/2009265.vec I:\\Data\\3Params\\OUTPUT/2009265_norm.vec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Data normalisation........... OK\n",
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" SOMLibVectorNormalization -m STANDARD_SCORE I:\\Data\\3Params\\OUTPUT/2009273.vec I:\\Data\\3Params\\OUTPUT/2009273_norm.vec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Data normalisation........... OK\n",
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" SOMLibVectorNormalization -m STANDARD_SCORE I:\\Data\\3Params\\OUTPUT/2009281.vec I:\\Data\\3Params\\OUTPUT/2009281_norm.vec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Data normalisation........... OK\n",
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" SOMLibVectorNormalization -m STANDARD_SCORE I:\\Data\\3Params\\OUTPUT/2009289.vec I:\\Data\\3Params\\OUTPUT/2009289_norm.vec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Data normalisation........... OK\n",
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" SOMLibVectorNormalization -m STANDARD_SCORE I:\\Data\\3Params\\OUTPUT/2009297.vec I:\\Data\\3Params\\OUTPUT/2009297_norm.vec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Data normalisation........... OK\n",
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" SOMLibVectorNormalization -m STANDARD_SCORE I:\\Data\\3Params\\OUTPUT/2009305.vec I:\\Data\\3Params\\OUTPUT/2009305_norm.vec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Data normalisation........... OK\n",
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" SOMLibVectorNormalization -m STANDARD_SCORE I:\\Data\\3Params\\OUTPUT/2009313.vec I:\\Data\\3Params\\OUTPUT/2009313_norm.vec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Data normalisation........... OK\n",
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" SOMLibVectorNormalization -m STANDARD_SCORE I:\\Data\\3Params\\OUTPUT/2009321.vec I:\\Data\\3Params\\OUTPUT/2009321_norm.vec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Data normalisation........... OK\n",
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" SOMLibVectorNormalization -m STANDARD_SCORE I:\\Data\\3Params\\OUTPUT/2009329.vec I:\\Data\\3Params\\OUTPUT/2009329_norm.vec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Data normalisation........... OK\n",
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" SOMLibVectorNormalization -m STANDARD_SCORE I:\\Data\\3Params\\OUTPUT/2009337.vec I:\\Data\\3Params\\OUTPUT/2009337_norm.vec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Data normalisation........... OK\n",
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" SOMLibVectorNormalization -m STANDARD_SCORE I:\\Data\\3Params\\OUTPUT/2009345.vec I:\\Data\\3Params\\OUTPUT/2009345_norm.vec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Data normalisation........... OK\n",
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" SOMLibVectorNormalization -m STANDARD_SCORE I:\\Data\\3Params\\OUTPUT/2009353.vec I:\\Data\\3Params\\OUTPUT/2009353_norm.vec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Data normalisation........... OK\n",
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" SOMLibVectorNormalization -m STANDARD_SCORE I:\\Data\\3Params\\OUTPUT/2009361.vec I:\\Data\\3Params\\OUTPUT/2009361_norm.vec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Data normalisation........... OK\n"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Next step is to normalise the values based on the standard deviation and to\n",
      "train the values as a unsupervised neural network mdoel also known as the\n",
      "Self-Organising Map. We use the software Java SOMToolbox developed at the\n",
      "Institute of Software Technology and Interactive System at the Vienna\n",
      "University of Technology."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def train():\n",
      "    paramstrain = [bat, \"GrowingSOM\", outpFiles+\"2009001.prop\"]\n",
      "    print sp.list2cmdline(paramstrain)\n",
      "    train = sp.Popen(sp.list2cmdline(paramstrain))\n",
      "    print \"Data training................ OK\"\n",
      "\n",
      "if os.path.isfile(outVecNorm):\n",
      "    train()\n",
      "else:\n",
      "    print 'no files to train'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" GrowingSOM I:\\Data\\3Params\\OUTPUT/2009001.prop\n",
        "Data training................ OK\n"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Viewing of the data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def view():\n",
      "    paramsview = [bat, \"SOMViewer\", '-u',\n",
      "                  outpFiles+\"2009001\\out001.unit.gz\", '-w',\n",
      "                  outpFiles+\"2009001\\out001.wgt.gz\",'--dw',\n",
      "                  outpFiles+\"2009001\\out001.dwm.gz\"]\n",
      "    print sp.list2cmdline(paramsview)\n",
      "    view = sp.Popen(sp.list2cmdline(paramsview))\n",
      "    print \"Trying to view data.......... OK\"\n",
      "\n",
      "print 'training of data is in progress..'\n",
      "\n",
      "if os.path.isfile(outpFiles+\"2009001\\out001.dwm.gz\"):\n",
      "    view()\n",
      "else:\n",
      "    print 'no files to view'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "training of data is in progress..\n",
        "\"C:/Program Files/SOMToolbox/somtoolbox.bat\" SOMViewer -u I:\\Data\\3Params\\OUTPUT/2009001\\out001.unit.gz -w I:\\Data\\3Params\\OUTPUT/2009001\\out001.wgt.gz --dw I:\\Data\\3Params\\OUTPUT/2009001\\out001.dwm.gz\n",
        "Trying to view data.......... OK"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Several different concept visualisation outputs for illustration purposes only. It's just testing of the different possibilties. Images are from today 24/7/2013. Different clusters are cleary visible. In the image with overview of all 6 variables gives nice overview. Even though it's not reliable since evtm file contains some very high values for urban areas, which should be filtered, for this reason the normalisation is biased and this results in a predominantly red map for the 'normal' values, with the biased high values as blue in the bottom left corner. Last six maps are the different component planes individually, with different colours. No labels are given but they are from left to right, top to bottom, tmin, tmax, prcp, ndvi, evtm, and lstm"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<img src=\"files/1.png\">\n",
      "<img src=\"files/2.png\">\n",
      "<img src=\"files/3.png\">\n",
      "<img src=\"files/4.png\">\n",
      "<img src=\"files/5.png\">\n",
      "<img src=\"files/6.png\">\n",
      "<img src=\"files/7tmin.png\">\n",
      "<img src=\"files/8tmax.png\">\n",
      "<img src=\"files/9prcp.png\">\n",
      "<img src=\"files/10ndvi.png\">\n",
      "<img src=\"files/11evtm.png\">\n",
      "<img src=\"files/12lstm.png\">"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}