{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import pandas as pd\n",
      "from osgeo import gdal\n",
      "import numpy as np\n",
      "import datetime\n",
      "import matplotlib.pyplot as plt\n",
      "from scipy.signal import detrend as sp_detrend\n",
      "import matplotlib.gridspec as gridspec\n",
      "import matplotlib.pyplot as pl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import datetime\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib as mpl\n",
      "import sys, os, re\n",
      "\n",
      "# Colors via http://colorbrewer2.com/\n",
      "WHITE, LIGHT_GRAY, GRAY, BLACK = [ \"#FFFFFF\", \"#E5E5E5\", \"#777777\", \"#000000\" ] \n",
      "COLORS = [ \"#FF6600\", \"#D7191C\", \"#2C7BB6\", \"#FFFFBF\", \"#ABD9E9\" ]\n",
      "ORANGE, RED, BLUE, YELLOW, LIGHT_BLUE = COLORS\n",
      "HIGH_ALPHA = 0.9\n",
      "MEDIUM_ALPHA = 0.5\n",
      "LOW_ALPHA = 0.1\n",
      "rgba = mpl.colors.colorConverter.to_rgba\n",
      "\n",
      "def set_styles(style_dict):\n",
      "    \"\"\"Set matplotlib styles from nested a nested dictionary\"\"\"\n",
      "    for obj in style_dict: mpl.rc(obj, **style_dict[obj]) \n",
      "\n",
      "set_styles({\n",
      "    \"figure\": { \"figsize\": [ 12, 8 ], \"facecolor\": WHITE },\n",
      "    \"savefig\": { \"dpi\": 200, \"bbox\": \"tight\" },\n",
      "    \"patch\": { \"linewidth\": 0.5, \"facecolor\": ORANGE, \"edgecolor\": WHITE, \"antialiased\": True },\n",
      "    \"font\": { \"size\": 8 },\n",
      "    \"legend\": { \"fontsize\": 10 },\n",
      "    \"axes\": { \n",
      "        \"facecolor\": LIGHT_GRAY, \n",
      "        \"edgecolor\": WHITE, \n",
      "        \"linewidth\": 1, \n",
      "        \"grid\": False, \n",
      "        \"titlesize\": \"large\", \n",
      "        \"labelsize\": \"large\", \n",
      "        \"labelcolor\": GRAY,\n",
      "        \"axisbelow\": True,\n",
      "        \"color_cycle\": COLORS\n",
      "    },\n",
      "    \"xtick\": { \"color\": GRAY, \"direction\": \"out\" },\n",
      "    \"ytick\": { \"color\": GRAY, \"direction\": \"out\" },\n",
      "    \"grid\": { \"color\": WHITE, \"linestyle\": \"-\" }\n",
      "})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def savitzky_golay(y, window_size, order, deriv=0, rate=1):\n",
      "    r\"\"\"Smooth (and optionally differentiate) data with a Savitzky-Golay filter.\n",
      "    The Savitzky-Golay filter removes high frequency noise from data.\n",
      "    It has the advantage of preserving the original shape and\n",
      "    features of the signal better than other types of filtering\n",
      "    approaches, such as moving averages techniques.\n",
      "    Parameters\n",
      "    ----------\n",
      "    y : array_like, shape (N,)\n",
      "        the values of the time history of the signal.\n",
      "    window_size : int\n",
      "        the length of the window. Must be an odd integer number.\n",
      "    order : int\n",
      "        the order of the polynomial used in the filtering.\n",
      "        Must be less then `window_size` - 1.\n",
      "    deriv: int\n",
      "        the order of the derivative to compute (default = 0 means only smoothing)\n",
      "    Returns\n",
      "    -------\n",
      "    ys : ndarray, shape (N)\n",
      "        the smoothed signal (or it's n-th derivative).\n",
      "    Notes\n",
      "    -----\n",
      "    The Savitzky-Golay is a type of low-pass filter, particularly\n",
      "    suited for smoothing noisy data. The main idea behind this\n",
      "    approach is to make for each point a least-square fit with a\n",
      "    polynomial of high order over a odd-sized window centered at\n",
      "    the point.\n",
      "    Examples\n",
      "    --------\n",
      "    t = np.linspace(-4, 4, 500)\n",
      "    y = np.exp( -t**2 ) + np.random.normal(0, 0.05, t.shape)\n",
      "    ysg = savitzky_golay(y, window_size=31, order=4)\n",
      "    import matplotlib.pyplot as plt\n",
      "    plt.plot(t, y, label='Noisy signal')\n",
      "    plt.plot(t, np.exp(-t**2), 'k', lw=1.5, label='Original signal')\n",
      "    plt.plot(t, ysg, 'r', label='Filtered signal')\n",
      "    plt.legend()\n",
      "    plt.show()\n",
      "    References\n",
      "    ----------\n",
      "    .. [1] A. Savitzky, M. J. E. Golay, Smoothing and Differentiation of\n",
      "       Data by Simplified Least Squares Procedures. Analytical\n",
      "       Chemistry, 1964, 36 (8), pp 1627-1639.\n",
      "    .. [2] Numerical Recipes 3rd Edition: The Art of Scientific Computing\n",
      "       W.H. Press, S.A. Teukolsky, W.T. Vetterling, B.P. Flannery\n",
      "       Cambridge University Press ISBN-13: 9780521880688\n",
      "    \"\"\"\n",
      "    import numpy as np\n",
      "    from math import factorial\n",
      "\n",
      "    try:\n",
      "        window_size = np.abs(np.int(window_size))\n",
      "        order = np.abs(np.int(order))\n",
      "    except ValueError as msg:\n",
      "        raise ValueError(\"window_size and order have to be of type int\")\n",
      "    if window_size % 2 != 1 or window_size < 1:\n",
      "        raise TypeError(\"window_size size must be a positive odd number\")\n",
      "    if window_size < order + 2:\n",
      "        raise TypeError(\"window_size is too small for the polynomials order\")\n",
      "    order_range = range(order+1)\n",
      "    half_window = (window_size -1) // 2\n",
      "    # precompute coefficients\n",
      "    b = np.mat([[k**i for i in order_range] for k in range(-half_window, half_window+1)])\n",
      "    m = np.linalg.pinv(b).A[deriv] * rate**deriv * factorial(deriv)\n",
      "    # pad the signal at the extremes with\n",
      "    # values taken from the signal itself\n",
      "    firstvals = y[0] - np.abs( y[1:half_window+1][::-1] - y[0] )\n",
      "    lastvals = y[-1] + np.abs(y[-half_window-1:-1][::-1] - y[-1])\n",
      "    y = np.concatenate((firstvals, y, lastvals))\n",
      "    return np.convolve( m[::-1], y, mode='valid')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def _datacheck_peakdetect(x_axis, y_axis):\n",
      "    if x_axis is None:\n",
      "        x_axis = range(len(y_axis))\n",
      "    \n",
      "    if len(y_axis) != len(x_axis):\n",
      "        raise (ValueError, \n",
      "                'Input vectors y_axis and x_axis must have same length')\n",
      "    \n",
      "    #needs to be a numpy array\n",
      "    y_axis = np.array(y_axis)\n",
      "    x_axis = np.array(x_axis)\n",
      "    return x_axis, y_axis"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def peakdetect(y_axis, x_axis = None, lookahead = 300, delta=0):\n",
      "    \"\"\"\n",
      "    Converted from/based on a MATLAB script at: \n",
      "    http://billauer.co.il/peakdet.html\n",
      "    \n",
      "    function for detecting local maximas and minmias in a signal.\n",
      "    Discovers peaks by searching for values which are surrounded by lower\n",
      "    or larger values for maximas and minimas respectively\n",
      "    \n",
      "    keyword arguments:\n",
      "    y_axis -- A list containg the signal over which to find peaks\n",
      "    x_axis -- (optional) A x-axis whose values correspond to the y_axis list\n",
      "        and is used in the return to specify the postion of the peaks. If\n",
      "        omitted an index of the y_axis is used. (default: None)\n",
      "    lookahead -- (optional) distance to look ahead from a peak candidate to\n",
      "        determine if it is the actual peak (default: 200) \n",
      "        '(sample / period) / f' where '4 >= f >= 1.25' might be a good value\n",
      "    delta -- (optional) this specifies a minimum difference between a peak and\n",
      "        the following points, before a peak may be considered a peak. Useful\n",
      "        to hinder the function from picking up false peaks towards to end of\n",
      "        the signal. To work well delta should be set to delta >= RMSnoise * 5.\n",
      "        (default: 0)\n",
      "            delta function causes a 20% decrease in speed, when omitted\n",
      "            Correctly used it can double the speed of the function\n",
      "    \n",
      "    return -- two lists [max_peaks, min_peaks] containing the positive and\n",
      "        negative peaks respectively. Each cell of the lists contains a tupple\n",
      "        of: (position, peak_value) \n",
      "        to get the average peak value do: np.mean(max_peaks, 0)[1] on the\n",
      "        results to unpack one of the lists into x, y coordinates do: \n",
      "        x, y = zip(*tab)\n",
      "    \"\"\"\n",
      "    max_peaks = []\n",
      "    min_peaks = []\n",
      "    dump = []   #Used to pop the first hit which almost always is false\n",
      "       \n",
      "    # check input data\n",
      "    x_axis, y_axis = _datacheck_peakdetect(x_axis, y_axis)\n",
      "    # store data length for later use\n",
      "    length = len(y_axis)\n",
      "    \n",
      "    \n",
      "    #perform some checks\n",
      "    if lookahead < 1:\n",
      "        raise ValueError ( \"Lookahead must be '1' or above in value\")\n",
      "    if not (np.isscalar(delta) and delta >= 0):\n",
      "        raise ValueError ( \"delta must be a positive number\" )\n",
      "    \n",
      "    #maxima and minima candidates are temporarily stored in\n",
      "    #mx and mn respectively\n",
      "    mn, mx = np.Inf, -np.Inf\n",
      "    \n",
      "    #Only detect peak if there is 'lookahead' amount of points after it\n",
      "    for index, (x, y) in enumerate(zip(x_axis[:-lookahead], \n",
      "                                        y_axis[:-lookahead])):\n",
      "        if y > mx:\n",
      "            mx = y\n",
      "            mxpos = x\n",
      "        if y < mn:\n",
      "            mn = y\n",
      "            mnpos = x\n",
      "        \n",
      "        ####look for max####\n",
      "        if y < mx-delta and mx != np.Inf:\n",
      "            #Maxima peak candidate found\n",
      "            #look ahead in signal to ensure that this is a peak and not jitter\n",
      "            if y_axis[index:index+lookahead].max() < mx:\n",
      "                max_peaks.append([mxpos, mx])\n",
      "                dump.append(True)\n",
      "                #set algorithm to only find minima now\n",
      "                mx = np.Inf\n",
      "                mn = np.Inf\n",
      "                if index+lookahead >= length:\n",
      "                    #end is within lookahead no more peaks can be found\n",
      "                    break\n",
      "                continue\n",
      "            #else:  #slows shit down this does\n",
      "            #    mx = ahead\n",
      "            #    mxpos = x_axis[np.where(y_axis[index:index+lookahead]==mx)]\n",
      "        \n",
      "        ####look for min####\n",
      "        if y > mn+delta and mn != -np.Inf:\n",
      "            #Minima peak candidate found \n",
      "            #look ahead in signal to ensure that this is a peak and not jitter\n",
      "            if y_axis[index:index+lookahead].min() > mn:\n",
      "                min_peaks.append([mnpos, mn])\n",
      "                dump.append(False)\n",
      "                #set algorithm to only find maxima now\n",
      "                mn = -np.Inf\n",
      "                mx = -np.Inf\n",
      "                if index+lookahead >= length:\n",
      "                    #end is within lookahead no more peaks can be found\n",
      "                    break\n",
      "            #else:  #slows shit down this does\n",
      "            #    mn = ahead\n",
      "            #    mnpos = x_axis[np.where(y_axis[index:index+lookahead]==mn)]\n",
      "    \n",
      "    \n",
      "    #Remove the false hit on the first value of the y_axis\n",
      "    try:\n",
      "        if dump[0]:\n",
      "            max_peaks.pop(0)\n",
      "        else:\n",
      "            min_peaks.pop(0)\n",
      "        del dump\n",
      "    except IndexError:\n",
      "        #no peaks were found, should the function return empty lists?\n",
      "        pass\n",
      "        \n",
      "    return [max_peaks, min_peaks]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def listall(RootFolder, wildcard=''):\n",
      "    lists = [os.path.join(root, name)    \n",
      "                 for root, dirs, files in os.walk(RootFolder)\n",
      "                   for name in files\n",
      "                   if wildcard in name\n",
      "                     if name.endswith('.tif')]\n",
      "    return lists\n",
      "\n",
      "def getvalues(rootpath, pc, pr, wildcard=''):\n",
      "    \n",
      "    li = []\n",
      "    da = []\n",
      "    i = 0\n",
      "    \n",
      "    #path = r'D:\\Data\\GPCP_30acc_AnnualAcc'\n",
      "    test = listall(rootpath, wildcard)\n",
      "    #test = test[0:-46]\n",
      "    print (len(test))\n",
      "    print (test[0])\n",
      "    for t in test:    \n",
      "        raster = gdal.Open(t, gdal.GA_ReadOnly)\n",
      "        nameRas = raster.GetDescription()[-11:-4]\n",
      "        date = datetime.datetime(int(nameRas[0:4]), 1, 1) + datetime.timedelta(int(nameRas[4:9]) - 1) # replaced \"int(nameRas[0:4])\" with \"2010\" first year then add doy\n",
      "        # print date\n",
      "        da.append(date)\n",
      "    \n",
      "        band = raster.GetRasterBand(1)\n",
      "        array = band.ReadAsArray()    \n",
      "        \n",
      "        # print array[879,4142] # Grassland pixel\n",
      "        li.append(array[pr, pc])\n",
      "        \n",
      "        array = None\n",
      "        band = None\n",
      "        raster = None\n",
      "        #print (str(i))\n",
      "        i = i + 1\n",
      "        \n",
      "    signal = pd.Series(data = li, index = da)\n",
      "    return signal"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mth = [0.5, 1, 2, 3, 4, 5]\n",
      "prd = [15, 30, 60, 90, 120, 150]\n",
      "pth1 = r'D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\TRMM2_2009\\XX_Day_Period\\XX_DaySums_StdNormAnomaly'# removed 'NormTypeII'\n",
      "pth2 = r'D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\NDVI_2009\\DaySums_StdNormAnomalyRes'# removed 'NormTypeII'\n",
      "\n",
      "#pixelcolumn = 23 # extract from rasterXSize (0:62) horizontal latitude - whatever\n",
      "#pixelrow = 21 # extract from rasterYSize (0:36) vertical longitude \n",
      "folderp1 = r'D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\PLOT_CHARTS_2009\\COHERENCE2//'\n",
      "folderp2 = r'D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\PLOT_CHARTS_2009\\COHERENCE2//'\n",
      "\n",
      "for j in range(22, 23): # pixelcolumn\n",
      "    for k in range(27,28): # pixelrow\n",
      "        for i in range(0,6):\n",
      "            # Set path for cumulative period of precipitation\n",
      "            # And corresponding period time\n",
      "            cumper = mth[i]\n",
      "            period = prd[i]\n",
      "            paths1 = pth1.replace('XX', str(period))\n",
      "            paths2 = pth2\n",
      "            print '\\n',paths1,'\\n', paths2, '\\n', cumper\n",
      "    \n",
      "            # Set pixelvalues\n",
      "            # TODO: Implementation to read row by row or all-in-one\n",
      "            pixelcolumn = j\n",
      "            pixelrow = k\n",
      "            \n",
      "            # Get values for precipitation based on cumper \n",
      "            # And only update values for NDVI with a new pixel\n",
      "            s_org1 = getvalues(paths1, pixelcolumn, pixelrow, wildcard='TRMM')\n",
      "            if i == 0:\n",
      "                s_org2 = getvalues(paths2, pixelcolumn, pixelrow, wildcard='CQ')\n",
      "            \n",
      "            # Create dataframe from the two series and apply an outer join            \n",
      "            df1 = pd.DataFrame(s_org1, columns=['prcp'])\n",
      "            df2 = pd.DataFrame(s_org2, columns=['ndvi'])            \n",
      "            df = pd.concat([df1, df2], join='outer', axis=1)\n",
      "            \n",
      "            # Before splitting the signals, first drop eventual NaN values\n",
      "            df = df.dropna()            \n",
      "            s1 = df['prcp']\n",
      "            s2 = df['ndvi']\n",
      "            \n",
      "            # In case of subsetting by a certain interval apply following:\n",
      "            # Get for each value the corresponding month and set these to 0\n",
      "            #month = df['prcp'].index.month\n",
      "            #selector = ((3<= month) & (month <=10)) # boolean array with True values for month 3 - 10\n",
      "            \n",
      "            #listsel = selector.tolist()\n",
      "            #listinv = [not i for i in listsel]\n",
      "            #selectorinv = np.array(listinv) # boolean array with False values for month 3 - 10\n",
      "            \n",
      "            #s1[selectorinv] = 0 # set month not equal to 3 - 10 to 0\n",
      "            #s2[selectorinv] = 0 # set month not equal to 3 - 10 to 0 \n",
      "            \n",
      "            # For blue noise filtering apply a higher order degree savitzky-golay filter \n",
      "            # with a window of 15 values\n",
      "            s1_SG = savitzky_golay(s1, 15, 7)\n",
      "            s2_SG = savitzky_golay(s2, 15, 7)\n",
      "            \n",
      "            # start signal processing\n",
      "            x = s1_SG\n",
      "            y = s2_SG\n",
      "            \n",
      "            # for interpolation use nfft window of 10 times total length\n",
      "            nfft = 10* x.size\n",
      "            \n",
      "            # copy values into thus zero padded array for both x and y\n",
      "            x_l = np.zeros(nfft)\n",
      "            x_l[0:x.size]= x            \n",
      "            y_l = np.zeros(nfft)\n",
      "            y_l[0:y.size]= y\n",
      "            \n",
      "            # calculate sampling period, sampling rate and frequecny resolution\n",
      "            dt = 1.# 2 # sampling period (d)\n",
      "            fs = 1. / dt # sampling rate (Hz)\n",
      "            fres = fs / nfft # frequency resolution (Hz)\n",
      "            \n",
      "            # calculate the frequency and time domain interval \n",
      "            L = x_l.size / 2 + 1\n",
      "            t_PSD = np.arange(0,L)\n",
      "            t_PSD_almost = t_PSD * fres # sampling rate: numper of cycles per second (Hz)\n",
      "            sp_t = 1 / (t_PSD_almost * (365/12.)) # period (min)\n",
      "            \n",
      "            # determine the length of both the series\n",
      "            nx = x_l.size\n",
      "            ny = y_l.size\n",
      "            \n",
      "            # compute fourier transform for real input, while firstly removing a linear trend \n",
      "            # of both the functions and apply a Bartlett window tappers the signal without creating\n",
      "            # too much ripples in the frequency domain\n",
      "            fft_x1 = np.fft.rfft(sp_detrend(x_l)*np.bartlett(nx))\n",
      "            fft_y1 = np.fft.rfft(sp_detrend(y_l)*np.bartlett(ny))\n",
      "            \n",
      "            # psd = |F_x*F_x(conj)|/N^2\n",
      "            psd_x1 = abs(fft_x1*fft_x1.conjugate())/nx**2\n",
      "            psd_y1 = abs(fft_y1*fft_y1.conjugate())/ny**2\n",
      "            \n",
      "            # csd = F_x(conj)*F_y\n",
      "            csd_x1y1 = fft_x1.conjugate() * fft_y1\n",
      "            \n",
      "            # phase = atan2(csd.imag, csd.real)\n",
      "            phase_x1y1 = np.angle(csd_x1y1)\n",
      "            \n",
      "            # convert timedate to matploblib values for xlim in plots\n",
      "            s_dt = matplotlib.dates.date2num( s_org1.index[0] )\n",
      "            e_dt = matplotlib.dates.date2num( s_org1.index[-1] )  \n",
      "        \n",
      "            fig = plt.figure(figsize=(15,11))            \n",
      "            \n",
      "            G = gridspec.GridSpec(4, 2)\n",
      "            \n",
      "            axes_1 = pl.subplot(G[0, :])\n",
      "            axes_1.axhline(y=0, color='0.5', linestyle='-')\n",
      "            axes_1.plot(s1.index,s1_SG, color=BLUE, label='Precipitation')\n",
      "            axes_1.plot(s2.index,s2_SG, color=ORANGE, label='NDVI')\n",
      "            axes_1.set_xlabel('Time (year)')\n",
      "            axes_1.set_ylabel('Anomaly difference')\n",
      "            axes_1.set_ylim([-0.8,0.8])\n",
      "            axes_1.set_yticks([-0.8, -0.6, -0.4, -0.2, 0, 0.2, 0.4, 0.6, 0.8])\n",
      "            axes_1.set_xlim([s_dt,e_dt])\n",
      "            axes_1.legend(fancybox=True, loc=4)\n",
      "            axes_1.set_title('Time-series Normalized Precipitation (CumPer '+str(cumper)+' months) and NDVI Anomaly')            \n",
      "            axes_1.grid(True)\n",
      "            \n",
      "            axes_2 = pl.subplot(G[1, 0:1])\n",
      "            axes_2.plot(t_PSD_almost, psd_x1, color=BLUE, lw=2, label='PSD Precipitation')\n",
      "            axes_2.set_title('Power Spectral Density in Frequency domain (Precipitation)')            \n",
      "            axes_2.set_xlabel('Frequency (Hz)')\n",
      "            axes_2.set_xlim([6.8493150684931506849315068493151e-4,0.005])\n",
      "            axes_2.set_xticks([0.001, 0.002, 0.003, 0.004, 0.005])\n",
      "            axes_2.set_ylim([0,3.5e-7])\n",
      "            axes_2.axvspan(1./395, 1./335, facecolor=GRAY, alpha=0.5)\n",
      "            axes_2.axvline(x=1./365, color=BLACK, lw=0.75)            \n",
      "            axes_2.axvspan(1./760.4, 1./699.6, facecolor=GRAY, alpha=0.5)\n",
      "            axes_2.axvline(x=1./730, color=WHITE, lw=0.75)            \n",
      "            axes_2.set_ylabel('PSD Precipitation ($Power$)')\n",
      "            axes_2.legend(fancybox=True)\n",
      "            axes_2.grid(True)\n",
      "            \n",
      "            axes_3 = pl.subplot(G[1, 1:2])\n",
      "            axes_3.plot(sp_t, psd_x1, color=BLUE, lw=2, label='PSD Precipitatation')#\n",
      "            axes_3.set_xlabel('Sampling period (months)')\n",
      "            axes_3.set_xlim([0,48])\n",
      "            axes_3.set_ylim([0,3.5e-7])\n",
      "            axes_3.axvspan(13, 11, facecolor=GRAY, alpha=0.5)\n",
      "            axes_3.axvline(x=12, color=BLACK, lw=0.75)\n",
      "            axes_3.axvspan(25, 23, facecolor=GRAY, alpha=0.5)\n",
      "            axes_3.axvline(x=24, color=WHITE, lw=0.75)\n",
      "            axes_3.set_xticks([6, 12, 18, 24, 30, 36, 42, 48])\n",
      "            axes_3.set_ylabel('PSD Precipitation ($Power$)')\n",
      "            axes_3.grid(True)\n",
      "            axes_3.legend(fancybox=True)\n",
      "            axes_3.set_title('Power Spectral Density in Time domain (Precipitation)')\n",
      "            \n",
      "            axes_4 = pl.subplot(G[2, 0:1])\n",
      "            axes_4.plot(t_PSD_almost, psd_y1, color=ORANGE, lw=2, label='PSD NDVI')\n",
      "            axes_4.set_xlabel('Frequency (Hz)')\n",
      "            axes_4.set_xlim([6.8493150684931506849315068493151e-4,0.005])\n",
      "            axes_4.set_xticks([0.001, 0.002, 0.003, 0.004, 0.005])\n",
      "            axes_4.set_ylim([0,3.5e-7])\n",
      "            axes_4.axvspan(1./395, 1./335, facecolor=GRAY, alpha=0.5)\n",
      "            axes_4.axvline(x=1./365, color=BLACK, lw=0.75)\n",
      "            axes_4.axvspan(1./760.4, 1./699.6, facecolor=GRAY, alpha=0.5)\n",
      "            axes_4.axvline(x=1./730, color=WHITE, lw=0.75)\n",
      "            axes_4.set_ylabel('PSD NDVI ($Power$)')\n",
      "            axes_4.grid(True)\n",
      "            axes_4.legend(fancybox=True)\n",
      "            axes_4.set_title('Power Spectral Density in Frequency domain (NDVI)')\n",
      "            \n",
      "            axes_5 = pl.subplot(G[2, 1:2])\n",
      "            axes_5.plot(sp_t, psd_y1, color=ORANGE, lw=2, label='PSD NDVI')#\n",
      "            axes_5.set_xlabel('Sampling period (months)')\n",
      "            axes_5.set_xlim([6,48])\n",
      "            axes_5.axvspan(13, 11, facecolor=GRAY, alpha=0.5)\n",
      "            axes_5.axvline(x=12, color=BLACK, lw=0.75)\n",
      "            axes_5.axvspan(25, 23, facecolor=GRAY, alpha=0.5)\n",
      "            axes_5.axvline(x=24, color=WHITE, lw=0.75)\n",
      "            axes_5.set_ylim([0,3.5e-7])\n",
      "            axes_5.set_xticks([6, 12, 18, 24, 30, 36, 42, 48])\n",
      "            axes_5.grid(True)\n",
      "            axes_5.set_ylabel('PSD NDVI ($Power$)')\n",
      "            axes_5.legend(fancybox=True)\n",
      "            axes_5.set_title('Power Spectral Density in Time domain (NDVI)')\n",
      "            \n",
      "            axes_6 = pl.subplot(G[3, 0:1])\n",
      "            axes_7 = axes_6.twinx()\n",
      "            axes_6.plot(t_PSD_almost, csd_x1y1, color=BLACK, lw=2, label='CSD')\n",
      "            axes_7.plot(t_PSD_almost, phase_x1y1, 'm.', label='Phase')\n",
      "            axes_6.set_xlabel('Frequency (Hz)')\n",
      "            axes_6.set_ylim([-250,250])\n",
      "            axes_6.set_yticks([-200, -100, 0 ,100, 200])\n",
      "            axes_6.set_xlim([6.8493150684931506849315068493151e-4,0.005])\n",
      "            axes_6.set_xticks([0.001, 0.002, 0.003, 0.004, 0.005])\n",
      "            axes_6.axvspan(1./395, 1./335, facecolor=GRAY, alpha=0.5)\n",
      "            axes_6.axvline(x=1./365, color=BLACK, lw=0.75)\n",
      "            axes_6.axvspan(1./760.4, 1./699.6, facecolor=GRAY, alpha=0.5)\n",
      "            axes_6.axvline(x=1./730, color=WHITE, lw=0.75)\n",
      "            axes_6.axhline(y=0, color=BLACK, linestyle='-', lw=1)\n",
      "            axes_6.set_ylabel('Cross-spectral power')\n",
      "            #for tl in axes_6.get_yticklabels():\n",
      "            #    tl.set_color('k')                \n",
      "            axes_7.set_ylabel('Phase (radian ($-\\pi:\\pi$)')\n",
      "            axes_7.set_ylim([-3.5,3.5])\n",
      "            axes_7.set_yticks([4*-np.pi/4.,2*-np.pi/4.,0,2*np.pi/4.,4*np.pi/4.])\n",
      "            axes_7.set_yticklabels(['$-\\pi$', r'$-\\frac{\\pi}{2}$', r'$0$', r'$\\frac{\\pi}{2}$', r'$+\\pi$'])\n",
      "            #for tl in axes_7.get_yticklabels():\n",
      "            #    tl.set_color('m')\n",
      "            axes_6.grid(True)\n",
      "            axes_7.grid(True)\n",
      "            leg6 = axes_6.legend(loc=2, fancybox=True)\n",
      "            leg7 = axes_7.legend(loc=4, fancybox=True)\n",
      "            axes_7.add_artist(leg6) \n",
      "            axes_6.legend = None \n",
      "            axes_6.set_title('Cross-Spectral Density and Phase Spectrum in Frequency domain')\n",
      "            \n",
      "            \n",
      "            axes_8 = pl.subplot(G[3, 1:2])\n",
      "            axes_9 = axes_8.twinx()\n",
      "            axes_8.plot(sp_t, csd_x1y1, color=BLACK, lw=2, label='CSD')\n",
      "            axes_9.plot(sp_t, phase_x1y1, 'm.', label='Phase')\n",
      "            axes_8.set_xlabel('Sampling period (months)')\n",
      "            axes_8.set_ylim([-250,250])\n",
      "            axes_8.set_yticks([-200, -100, 0 ,100, 200])\n",
      "            axes_8.set_xlim([6,48])\n",
      "            axes_8.set_xticks([6, 12, 18, 24, 30, 36, 42, 48])\n",
      "            axes_8.axvspan(13, 11, facecolor=GRAY, alpha=0.5)\n",
      "            axes_8.axvline(x=12, color=BLACK, lw=0.75)\n",
      "            axes_8.axvspan(25, 23, facecolor=GRAY, alpha=0.5)\n",
      "            axes_8.axvline(x=24, color=WHITE, lw=0.75)\n",
      "            axes_8.axhline(y=0, color=BLACK, linestyle='-', lw=1)\n",
      "            axes_8.set_ylabel('Cross-spectral power')\n",
      "            #for tl in axes_8.get_yticklabels():\n",
      "            #    tl.set_color('k')\n",
      "            axes_9.set_ylabel('Phase (radian ($-\\pi:\\pi$)')\n",
      "            axes_9.set_ylim([-3.5,3.5])\n",
      "            axes_9.set_yticks([4.*-np.pi/4.,2.*-np.pi/4.,0,2.*np.pi/4.,4.*np.pi/4.])\n",
      "            axes_9.set_yticklabels(['$-\\pi$', r'$-\\frac{\\pi}{2}$', r'$0$', r'$\\frac{\\pi}{2}$', r'$+\\pi$'])            \n",
      "            #for tl in axes_9.get_yticklabels():\n",
      "            #    tl.set_color('m')\n",
      "            axes_8.grid(True)\n",
      "            axes_9.grid(True)\n",
      "            leg8 = axes_8.legend(loc=2, fancybox=True)\n",
      "            leg9 = axes_9.legend(loc=4, fancybox=True)\n",
      "            axes_9.add_artist(leg8) \n",
      "            axes_8.legend = None     \n",
      "            axes_8.set_title('Cross-Spectral Density and Phase Spectrum in Time domain')\n",
      "            \n",
      "            pl.tight_layout()\n",
      "            \n",
      "            fileou = 'Charts_Col'+str(pixelcolumn)+'Row'+str(pixelrow)+'CumPer'+str(cumper)+'_part1.png'\n",
      "            path = folderp1+fileou\n",
      "            \n",
      "            print(path)\n",
      "            plt.savefig(path, dpi=200)\n",
      "            plt.close(fig)\n",
      "            fig.clf()\n",
      "            #plt.show()\n",
      "\n",
      "            # detection by lookaround peakdetector in frequency domain\n",
      "            _maxfr, _minfr = peakdetect(csd_x1y1, t_PSD_almost, 2)#10, 0.30)\n",
      "            xmfr = np.array([p[0] for p in _maxfr])\n",
      "            ymfr = np.array([p[1] for p in _maxfr])\n",
      "            \n",
      "            # detection by lookaround peakdetector in time domain\n",
      "            _maxpr, _minpr = peakdetect(csd_x1y1, sp_t, 2)#10, 0.30)\n",
      "            xmpr = np.array([p[0] for p in _maxpr])\n",
      "            ympr = np.array([p[1] for p in _maxpr])\n",
      "            \n",
      "            try:\n",
      "                # select the index values of the peaks that are \n",
      "                # within the range of biennial period in time domain\n",
      "                prd_2 = xmpr[(xmpr >= (1./0.0015)/(365/12)) & (xmpr <= (1./0.00125)/(365/12))]\n",
      "                prd_2 = max(prd_2)\n",
      "                \n",
      "                # select the index values of the peak that is most near \n",
      "                # the biennial period in frequency domain\n",
      "                frq_2 = xmfr[(xmfr >= 0.00125) & (xmfr <= 0.0015)]\n",
      "                frq_2 = max(frq_2)\n",
      "                \n",
      "                # select the coressponding csd value of the peak for biennial period\n",
      "                csd_2 = ymfr[(xmfr >= 0.00125) & (xmfr <= 0.0015)]\n",
      "                csd_2 = max(csd_2)\n",
      "                \n",
      "                # select the phase in radian coressponding to the biennial peak\n",
      "                phs_2 = phase_x1y1[t_PSD_almost==frq_2]\n",
      "            except ValueError:\n",
      "                prd_2 = 0\n",
      "                frq_2 = 0\n",
      "                csd_2 = 0\n",
      "                phs_2 = 0\n",
      "\n",
      "            \n",
      "            try:\n",
      "                # select the index values of the peaks that are \n",
      "                # within the range of annual period in time domain\n",
      "                prd_1 = xmpr[(xmpr >= (1./0.0035)/(365/12)) & (xmpr <= (1./0.0025)/(365/12))]\n",
      "                prd_1 = max(prd_1)\n",
      "    \n",
      "                # select the index values of the peak that is most near \n",
      "                # the annual period in frequency domain\n",
      "                frq_1 = xmfr[(xmfr >= 0.0025) & (xmfr <= 0.0035)]\n",
      "                frq_1 = max(frq_1)\n",
      "    \n",
      "                # select the coressponding csd value of the peak for annual period\n",
      "                csd_1 = ymfr[(xmfr >= 0.0025) & (xmfr <= 0.0035)]\n",
      "                csd_1 = max(csd_1)\n",
      "                \n",
      "                # select the phase in radian coressponding to the annual peak\n",
      "                phs_1 = phase_x1y1[t_PSD_almost==frq_1]\n",
      "            except ValueError:\n",
      "                prd_1 = 0\n",
      "                frq_1 = 0\n",
      "                csd_1 = 0\n",
      "                phs_1 = 0                \n",
      "            \n",
      "            # set time increments in physcial units (days)\n",
      "            t = np.arange(0,len(s1_SG),1)\n",
      "            \n",
      "            # convert phase lag in radian to days for annual period\n",
      "            # and create original sinus signal and shifted signal\n",
      "            prdm1 = prd_1*(365/12)\n",
      "            phd_1 = (365/2.)*phs_1/np.pi\n",
      "            sorg1 = 0.5 *sin(2*(np.pi/(365)) * t)#prdm1\n",
      "            sshf1 = 0.5 *sin(2*(np.pi/(365)) * t - phs_1)#prdm1\n",
      "\n",
      "            # convert phase lag in radian to days for biennial period\n",
      "            # and create original sinus signal and shifted signal\n",
      "            phd_2 = (730/2.)*phs_2/np.pi\n",
      "            prdm2 = prd_2*(365/12)\n",
      "            sorg2 = 0.5 *sin(2*(np.pi/(365*2)) * t)#prdm2\n",
      "            sshf2 = 0.5 *sin(2*(np.pi/(365*2)) * t - phs_2)#prdm2\n",
      "            \n",
      "            fig = plt.figure(figsize=(15,11))\n",
      "            \n",
      "            #pl.figure(figsize=(6, 4))\n",
      "            G = gridspec.GridSpec(4, 2)\n",
      "            \n",
      "            axes_1 = pl.subplot(G[0, 0:1])\n",
      "            axes_1.axhline(y=0, color='0.5', linestyle='--')\n",
      "            axes_1.axvline(x=frq_1, color='c', linewidth='2', linestyle='-')\n",
      "            axes_1.axvline(x=frq_2, color='g', linewidth='2', linestyle='-')\n",
      "            axes_1.plot(t_PSD_almost, csd_x1y1, 'k-', label='CSD') # CCF\n",
      "            axes_1.plot(xmfr, ymfr, 'ro', markersize=6, label='Peaks') # peaks lookaround function\n",
      "            axes_1.set_xlim([6.8493150684931506849315068493151e-4,0.005])\n",
      "            axes_1.set_xticks([0.001, 0.002, 0.003, 0.004, 0.005])\n",
      "            axes_1.set_title('Cross-Spectral Density in Frequency domain')\n",
      "            axes_1.set_xlabel('Frequency (Hz)')\n",
      "            axes_1.set_ylabel('Cross-spectral Power')\n",
      "            axes_1.legend(fancybox=True, loc=4)\n",
      "            axes_1.grid()\n",
      "            \n",
      "            axes_2 = pl.subplot(G[0, 1:2])\n",
      "            axes_2.axhline(y=0, color='0.5', linestyle='--')\n",
      "            axes_2.axvline(x=prd_1, color='c', linewidth='2', linestyle='-')\n",
      "            axes_2.axvline(x=prd_2, color='g', linewidth='2', linestyle='-')\n",
      "            axes_2.plot(sp_t, csd_x1y1, 'k-', label='CSD') # CCF\n",
      "            axes_2.plot(xmpr, ympr, 'ro', markersize=6, label='Peaks') # peaks lookaround function\n",
      "            axes_2.set_xlim(6,48)\n",
      "            axes_2.set_xticks([6, 12, 18, 24, 30, 36, 42, 48])\n",
      "            axes_2.set_title('Cross-Spectral Density in Time domain')\n",
      "            axes_2.set_ylabel('Cross-spectral Power')\n",
      "            axes_2.set_xlabel('Sampling period (months)')\n",
      "            axes_2.legend(fancybox=True, loc=4)\n",
      "            axes_2.grid()\n",
      "            \n",
      "            axes_3 = pl.subplot(G[1, :])\n",
      "            axes_3.axhline(y=0, color='0.5', linestyle='--')\n",
      "            axes_3.plot(s1.index,s1_SG, label='Precipitation')\n",
      "            axes_3.plot(s1.index,s2_SG, label='NDVI')\n",
      "            axes_3.set_xlim([s_dt,e_dt])\n",
      "            axes_3.set_title('Time-series Normalized Precipitation (CumPer '+str(cumper)+' months) and NDVI Anomaly')\n",
      "            axes_3.legend(fancybox=True, loc=4)\n",
      "            axes_3.set_xlabel('Time (year)')\n",
      "            axes_3.set_ylabel('Anomaly difference')\n",
      "            axes_3.grid()\n",
      "            \n",
      "            axes_4 = pl.subplot(G[2, :])\n",
      "            axes_4.axhline(y=0, color='0.5', linestyle='--')\n",
      "            axes_4.plot(s1.index,s1_SG, '0.4', linestyle='-')\n",
      "            axes_4.plot(s1.index,s2_SG, '0.4', linestyle='--')\n",
      "            axes_4.plot(s1.index,sorg1, label='Prec. base (annual)')\n",
      "            axes_4.plot(s1.index,sshf1, label='NDVI shifted (annual)')\n",
      "            axes_4.set_xlim([s_dt,e_dt])\n",
      "            axes_4.set_title('Annual Period + Phase Lag ('+str(int(phd_1))+' days)')\n",
      "            axes_4.legend(fancybox=True, loc=4)\n",
      "            axes_4.set_xlabel('Time (year)')\n",
      "            axes_4.set_ylabel('Anomaly difference')\n",
      "            axes_4.grid()\n",
      "            \n",
      "            axes_5 = pl.subplot(G[3, :])\n",
      "            axes_5.axhline(y=0, color='0.5', linestyle='--')\n",
      "            axes_5.plot(s1.index,s1_SG, '0.4', linestyle='-')\n",
      "            axes_5.plot(s1.index,s2_SG, '0.4', linestyle='--')\n",
      "            axes_5.plot(s1.index,sorg2, label='Prec. base (bieenial)')\n",
      "            axes_5.plot(s1.index,sshf2, label='NDVI. shifted (bieenial)')\n",
      "            axes_5.set_xlim([s_dt,e_dt])\n",
      "            axes_5.set_title('Biennial Period + Phase Lag ('+str(int(phd_2))+' days)')\n",
      "            axes_5.legend(fancybox=True, loc=4)\n",
      "            axes_5.set_xlabel('Time (year)')\n",
      "            axes_5.set_ylabel('Anomaly difference')\n",
      "            axes_5.grid()\n",
      "            \n",
      "            plt.tight_layout()\n",
      "            fileou = 'Charts_Col'+str(pixelcolumn)+'Row'+str(pixelrow)+'CumPer'+str(cumper)+'_part2.png'\n",
      "            path = folderp2+fileou\n",
      "            \n",
      "            print(path)\n",
      "            plt.savefig(path, dpi=200)\n",
      "            plt.close(fig)\n",
      "            fig.clf()\n",
      "            #plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\TRMM2_2009\\15_Day_Period\\15_DaySums_StdNormAnomaly \n",
        "D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\NDVI_2009\\DaySums_StdNormAnomalyRes \n",
        "0.5\n",
        "365\n",
        "D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\TRMM2_2009\\15_Day_Period\\15_DaySums_StdNormAnomaly\\TRMM_IM_2009001.tif\n",
        "365"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\NDVI_2009\\DaySums_StdNormAnomalyRes\\TRMM_CQ_2009001.tif\n",
        "D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\PLOT_CHARTS_2009\\COHERENCE2//Charts_Col22Row27CumPer0.5_part1.png"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\PLOT_CHARTS_2009\\COHERENCE2//Charts_Col22Row27CumPer0.5_part2.png"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\TRMM2_2009\\30_Day_Period\\30_DaySums_StdNormAnomaly \n",
        "D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\NDVI_2009\\DaySums_StdNormAnomalyRes \n",
        "1\n",
        "365\n",
        "D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\TRMM2_2009\\30_Day_Period\\30_DaySums_StdNormAnomaly\\TRMM_IM_2009001.tif\n",
        "D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\PLOT_CHARTS_2009\\COHERENCE2//Charts_Col22Row27CumPer1_part1.png"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\PLOT_CHARTS_2009\\COHERENCE2//Charts_Col22Row27CumPer1_part2.png"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\TRMM2_2009\\60_Day_Period\\60_DaySums_StdNormAnomaly \n",
        "D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\NDVI_2009\\DaySums_StdNormAnomalyRes \n",
        "2\n",
        "365\n",
        "D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\TRMM2_2009\\60_Day_Period\\60_DaySums_StdNormAnomaly\\TRMM_IM_2009001.tif\n",
        "D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\PLOT_CHARTS_2009\\COHERENCE2//Charts_Col22Row27CumPer2_part1.png"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\PLOT_CHARTS_2009\\COHERENCE2//Charts_Col22Row27CumPer2_part2.png"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\TRMM2_2009\\90_Day_Period\\90_DaySums_StdNormAnomaly \n",
        "D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\NDVI_2009\\DaySums_StdNormAnomalyRes \n",
        "3\n",
        "365\n",
        "D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\TRMM2_2009\\90_Day_Period\\90_DaySums_StdNormAnomaly\\TRMM_IM_2009001.tif\n",
        "D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\PLOT_CHARTS_2009\\COHERENCE2//Charts_Col22Row27CumPer3_part1.png"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\PLOT_CHARTS_2009\\COHERENCE2//Charts_Col22Row27CumPer3_part2.png"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\TRMM2_2009\\120_Day_Period\\120_DaySums_StdNormAnomaly \n",
        "D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\NDVI_2009\\DaySums_StdNormAnomalyRes \n",
        "4\n",
        "365\n",
        "D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\TRMM2_2009\\120_Day_Period\\120_DaySums_StdNormAnomaly\\TRMM_IM_2009001.tif\n",
        "D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\PLOT_CHARTS_2009\\COHERENCE2//Charts_Col22Row27CumPer4_part1.png"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\PLOT_CHARTS_2009\\COHERENCE2//Charts_Col22Row27CumPer4_part2.png"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\TRMM2_2009\\150_Day_Period\\150_DaySums_StdNormAnomaly \n",
        "D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\NDVI_2009\\DaySums_StdNormAnomalyRes \n",
        "5\n",
        "365\n",
        "D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\TRMM2_2009\\150_Day_Period\\150_DaySums_StdNormAnomaly\\TRMM_IM_2009001.tif\n",
        "D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\PLOT_CHARTS_2009\\COHERENCE2//Charts_Col22Row27CumPer5_part1.png"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\PLOT_CHARTS_2009\\COHERENCE2//Charts_Col22Row27CumPer5_part2.png"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s_org1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}