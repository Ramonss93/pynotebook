{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# -*- coding: utf-8 -*-\n",
      "# <nbformat>3.0</nbformat>\n",
      "\n",
      "# <codecell>\n",
      "from __future__ import division\n",
      "from libtfr import dpss\n",
      "from scipy.io import loadmat,savemat\n",
      "import scipy.interpolate as inter\n",
      "from numpy import *\n",
      "import pymat2\n",
      "import os\n",
      "import pandas as pd\n",
      "from osgeo import gdal\n",
      "import numpy as np\n",
      "import datetime\n",
      "import matplotlib.pyplot as plt\n",
      "from scipy.signal import detrend as sp_detrend\n",
      "import matplotlib.gridspec as gridspec\n",
      "import matplotlib.pyplot as pl\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import scipy.signal as sig\n",
      "import scipy.stats.distributions as dist\n",
      "\n",
      "import nitime.algorithms as tsa\n",
      "import nitime.utils as utils\n",
      "from nitime.viz import winspect\n",
      "from nitime.viz import plot_spectral_estimate\n",
      "\n",
      "import datetime\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib as mpl\n",
      "import sys, os, re\n",
      "from scipy import stats\n",
      "\n",
      "# <codecell>\n",
      "\n",
      "def saveRaster(path, array, dsSource, datatype=3, formatraster=\"GTiff\", nan=None): \n",
      "    \"\"\"\n",
      "    Datatypes:\n",
      "    unknown = 0\n",
      "    byte = 1\n",
      "    unsigned int16 = 2\n",
      "    signed int16 = 3\n",
      "    unsigned int32 = 4\n",
      "    signed int32 = 5\n",
      "    float32 = 6\n",
      "    float64 = 7\n",
      "    complex int16 = 8\n",
      "    complex int32 = 9\n",
      "    complex float32 = 10\n",
      "    complex float64 = 11\n",
      "    float32 = 6, \n",
      "    signed int = 3\n",
      "    \n",
      "    Formatraster:\n",
      "    GeoTIFF = GTiff\n",
      "    Erdas = HFA (output = .img)\n",
      "    OGC web map service = WMS\n",
      "    png = PNG\n",
      "    \"\"\"\n",
      "    # Set Driver\n",
      "    format_ = formatraster #save as format\n",
      "    driver = gdal.GetDriverByName( format_ )\n",
      "    driver.Register()\n",
      "    \n",
      "    # Set Metadata for Raster output\n",
      "    cols = dsSource.RasterXSize\n",
      "    rows = dsSource.RasterYSize\n",
      "    bands = dsSource.RasterCount\n",
      "    datatype = datatype#band.DataType\n",
      "    \n",
      "    # Set Projection for Raster\n",
      "    outDataset = driver.Create(path, cols, rows, bands, datatype)\n",
      "    geoTransform = dsSource.GetGeoTransform()\n",
      "    outDataset.SetGeoTransform(geoTransform)\n",
      "    proj = dsSource.GetProjection()\n",
      "    outDataset.SetProjection(proj)\n",
      "    \n",
      "    # Write output to band 1 of new Raster and write NaN value\n",
      "    outBand = outDataset.GetRasterBand(1)\n",
      "    if nan != None:\n",
      "        outBand.SetNoDataValue(nan)\n",
      "    outBand.WriteArray(array) #save input array\n",
      "    #outBand.WriteArray(dem)\n",
      "    \n",
      "    # Close and finalise newly created Raster\n",
      "    #F_M01 = None\n",
      "    outBand = None\n",
      "    proj = None\n",
      "    geoTransform = None\n",
      "    outDataset = None\n",
      "    driver = None\n",
      "    datatype = None\n",
      "    bands = None\n",
      "    rows = None\n",
      "    cols = None\n",
      "    driver = None\n",
      "    array = None\n",
      "\n",
      "# <codecell>\n",
      "\n",
      "# Colors via http://colorbrewer2.com/\n",
      "WHITE, LIGHT_GRAY, GRAY, BLACK = [ \"#FFFFFF\", \"#E5E5E5\", \"#777777\", \"#000000\" ] \n",
      "COLORS = [ \"#2C7BB6\", \"#FF6600\", \"#660099\", \"#D7191C\", \"#FFFFBF\", \"#ABD9E9\"]\n",
      "BLUE, ORANGE, PURPLE, RED, YELLOW, LIGHT_BLUE = COLORS\n",
      "HIGH_ALPHA = 0.9\n",
      "MEDIUM_ALPHA = 0.5\n",
      "LOW_ALPHA = 0.1\n",
      "rgba = mpl.colors.colorConverter.to_rgba\n",
      "\n",
      "def set_styles(style_dict):\n",
      "    \"\"\"Set matplotlib styles from nested a nested dictionary\"\"\"\n",
      "    for obj in style_dict: mpl.rc(obj, **style_dict[obj]) \n",
      "\n",
      "set_styles({\n",
      "    \"figure\": { \"figsize\": [ 12, 4 ], \"facecolor\": WHITE },\n",
      "    \"savefig\": { \"dpi\": 200, \"bbox\": \"tight\" },\n",
      "    \"patch\": { \"linewidth\": 0.5, \"facecolor\": ORANGE, \"edgecolor\": WHITE, \"antialiased\": True },\n",
      "    \"font\": { \"size\": 8 },\n",
      "    \"legend\": { \"fontsize\": 10 },\n",
      "    \"axes\": { \n",
      "        \"facecolor\": LIGHT_GRAY, \n",
      "        \"edgecolor\": WHITE, \n",
      "        \"linewidth\": 1, \n",
      "        \"grid\": False, \n",
      "        \"titlesize\": \"large\", \n",
      "        \"labelsize\": \"large\", \n",
      "        \"labelcolor\": BLACK,\n",
      "        \"axisbelow\": True,\n",
      "        \"color_cycle\": COLORS\n",
      "    },\n",
      "    \"xtick\": { \"color\": WHITE, \"direction\": \"out\" }, #GRAY\n",
      "    \"ytick\": { \"color\": WHITE, \"direction\": \"out\" }, #GRAY\n",
      "    \"grid\": { \"color\": WHITE, \"linestyle\": \"-\" }\n",
      "})\n",
      "\n",
      "# <codecell>\n",
      "\n",
      "def savitzky_golay(y, window_size, order, deriv=0, rate=1):\n",
      "    r\"\"\"Smooth (and optionally differentiate) data with a Savitzky-Golay filter.\n",
      "    The Savitzky-Golay filter removes high frequency noise from data.\n",
      "    It has the advantage of preserving the original shape and\n",
      "    features of the signal better than other types of filtering\n",
      "    approaches, such as moving averages techniques.\n",
      "    Parameters\n",
      "    ----------\n",
      "    y : array_like, shape (N,)\n",
      "        the values of the time history of the signal.\n",
      "    window_size : int\n",
      "        the length of the window. Must be an odd integer number.\n",
      "    order : int\n",
      "        the order of the polynomial used in the filtering.\n",
      "        Must be less then `window_size` - 1.\n",
      "    deriv: int\n",
      "        the order of the derivative to compute (default = 0 means only smoothing)\n",
      "    Returns\n",
      "    -------\n",
      "    ys : ndarray, shape (N)\n",
      "        the smoothed signal (or it's n-th derivative).\n",
      "    Notes\n",
      "    -----\n",
      "    The Savitzky-Golay is a type of low-pass filter, particularly\n",
      "    suited for smoothing noisy data. The main idea behind this\n",
      "    approach is to make for each point a least-square fit with a\n",
      "    polynomial of high order over a odd-sized window centered at\n",
      "    the point.\n",
      "    Examples\n",
      "    --------\n",
      "    t = np.linspace(-4, 4, 500)\n",
      "    y = np.exp( -t**2 ) + np.random.normal(0, 0.05, t.shape)\n",
      "    ysg = savitzky_golay(y, window_size=31, order=4)\n",
      "    import matplotlib.pyplot as plt\n",
      "    plt.plot(t, y, label='Noisy signal')\n",
      "    plt.plot(t, np.exp(-t**2), 'k', lw=1.5, label='Original signal')\n",
      "    plt.plot(t, ysg, 'r', label='Filtered signal')\n",
      "    plt.legend()\n",
      "    plt.show()\n",
      "    References\n",
      "    ----------\n",
      "    .. [1] A. Savitzky, M. J. E. Golay, Smoothing and Differentiation of\n",
      "       Data by Simplified Least Squares Procedures. Analytical\n",
      "       Chemistry, 1964, 36 (8), pp 1627-1639.\n",
      "    .. [2] Numerical Recipes 3rd Edition: The Art of Scientific Computing\n",
      "       W.H. Press, S.A. Teukolsky, W.T. Vetterling, B.P. Flannery\n",
      "       Cambridge University Press ISBN-13: 9780521880688\n",
      "    \"\"\"\n",
      "    import numpy as np\n",
      "    from math import factorial\n",
      "\n",
      "    try:\n",
      "        window_size = np.abs(np.int(window_size))\n",
      "        order = np.abs(np.int(order))\n",
      "    except ValueError as msg:\n",
      "        raise ValueError(\"window_size and order have to be of type int\")\n",
      "    if window_size % 2 != 1 or window_size < 1:\n",
      "        raise TypeError(\"window_size size must be a positive odd number\")\n",
      "    if window_size < order + 2:\n",
      "        raise TypeError(\"window_size is too small for the polynomials order\")\n",
      "    order_range = range(order+1)\n",
      "    half_window = (window_size -1) // 2\n",
      "    # precompute coefficients\n",
      "    b = np.mat([[k**i for i in order_range] for k in range(-half_window, half_window+1)])\n",
      "    m = np.linalg.pinv(b).A[deriv] * rate**deriv * factorial(deriv)\n",
      "    # pad the signal at the extremes with\n",
      "    # values taken from the signal itself\n",
      "    firstvals = y[0] - np.abs( y[1:half_window+1][::-1] - y[0] )\n",
      "    lastvals = y[-1] + np.abs(y[-half_window-1:-1][::-1] - y[-1])\n",
      "    y = np.concatenate((firstvals, y, lastvals))\n",
      "    return np.convolve( m[::-1], y, mode='valid')\n",
      "\n",
      "# <codecell>\n",
      "\n",
      "def listall(RootFolder, wildcard=''):\n",
      "    lists = [os.path.join(root, name)    \n",
      "                 for root, dirs, files in os.walk(RootFolder)\n",
      "                   for name in files\n",
      "                   if wildcard in name\n",
      "                     if name.endswith('.TIF')]\n",
      "    return lists\n",
      "\n",
      "def getvalues(rootpath, pc, pr, wildcard=''):\n",
      "    \n",
      "    li = []\n",
      "    da = []\n",
      "    i = 0\n",
      "    \n",
      "    #path = r'D:\\Data\\GPCP_30acc_AnnualAcc'\n",
      "    test = listall(rootpath, wildcard)\n",
      "    #test = test[0:-46]\n",
      "    #print (len(test))\n",
      "    #print (test[0])\n",
      "    for t in test:    \n",
      "        raster = gdal.Open(t, gdal.GA_ReadOnly)\n",
      "        nameRas = raster.GetDescription()[-11:-4]\n",
      "        date = datetime.datetime(int(nameRas[0:4]), 1, 1) + datetime.timedelta(int(nameRas[4:9]) - 1) # replaced \"int(nameRas[0:4])\" with \"2010\" first year then add doy\n",
      "        # print date\n",
      "        da.append(date)\n",
      "    \n",
      "        band = raster.GetRasterBand(1)\n",
      "        array = band.ReadAsArray()    \n",
      "        \n",
      "        # print array[879,4142] # Grassland pixel\n",
      "        li.append(array[pr, pc])\n",
      "        \n",
      "        array = None\n",
      "        band = None\n",
      "        raster = None\n",
      "        #print (str(i))\n",
      "        i = i + 1\n",
      "        \n",
      "    signal = pd.Series(data = li, index = da)\n",
      "    return signal\n",
      "\n",
      "# <codecell>\n",
      "\n",
      "def cohbias(v,cb):\n",
      "    if v < 2:\n",
      "        print 'Warning: degrees of freedom must be greater or equal to two'        \n",
      "    if cb.all() <0 or cb.all() > 1 :\n",
      "        print 'Warning: biased coherence should be between zero and one'        \n",
      "    if v > 50:\n",
      "        print 'Using 50 degrees of freedom'\n",
      "        v = 50\n",
      "    path_cb = r'C:\\Users\\lenovo\\Downloads\\Archives\\smop-master\\smop-master\\smop//cohbias'\n",
      "    lm = loadmat(path_cb, )\n",
      "    expect = lm.get('expect')\n",
      "    n = lm.get('n')\n",
      "    c = lm.get('c')\n",
      "    #print c.shape, n.shape, expect.shape\n",
      "    \n",
      "    cb=cb[:]\n",
      "    c=c.ravel()\n",
      "    n=n.ravel()\n",
      "    v=v\n",
      "    \n",
      "    ec=np.zeros_like(c)\n",
      "    for ct in xrange(len(c)):    \n",
      "        f = inter.interp1d(n,expect[:,ct], kind='linear')\n",
      "        ec[ct] = f(v)\n",
      "    \n",
      "    cu = np.zeros_like(cb)    \n",
      "    f = inter.interp1d(ec,c, kind='linear')#c,ec\n",
      "    for ct in xrange(len(cb)):      \n",
      "        try:\n",
      "            cu[ct] = f(cb[ct])\n",
      "        except ValueError:\n",
      "            cu[ct] = 0\n",
      "    \n",
      "    pl = np.where(isnan(cu) & (cb >=0) & (cb < 1))\n",
      "    cu[pl]=0\n",
      "    return cu\n",
      "\n",
      "# <codecell>\n",
      "\n",
      "\n",
      "\n",
      "def cmtm(x,y,dt=1,NW=8,qbias=0,confn=0):\n",
      "\n",
      "    \"\"\"\n",
      "    Multi-taper method coherence using adaptive weighting and correcting for the bias inherent to coherence estimates.  \n",
      "    The 95 coherence confidence level is computed by cohconf.m.  In addition, a built-in Monte Carlo estimation procedure \n",
      "    is available to estimate phase 95 confidence limits. \n",
      "\n",
      "    Inputs:\n",
      "    x     - Input data vector 1.  \n",
      "    y     - Input data vector 2.  \n",
      "    dt    - Sampling interval (default 1) \n",
      "    NW    - Number of windows to use (default 8) \n",
      "    qbias - Correct coherence estimate for bias (yes, 1)  (no, 0, default).\n",
      "    confn - Number of iterations to use in estimating phase uncertainty using a \n",
      "            Monte Carlomethod. (default 0)\n",
      "\n",
      "    Outputs:\n",
      "    s     - frequency\n",
      "    c     - coherence\n",
      "    ph    - phase\n",
      "    ci    - 95 coherence confidence level\n",
      "    phi   - 95 phase confidence interval, bias corrected (add and subtract phi \n",
      "            from ph).\n",
      "    \"\"\"\n",
      "    if NW<4:\n",
      "        NW=8\n",
      "    x = x - x.mean()\n",
      "    y = y - y.mean()\n",
      "    \n",
      "    #define some parameters\n",
      "    N = x.size \n",
      "    k = np.minimum(round(2*NW), N)\n",
      "    k = int(np.maximum(k-1,1))\n",
      "    s = np.linspace(0.0,1./1-1./(N*dt), N)\n",
      "    pls = np.arange(2,(N+1)/2+1)\n",
      "    pls = pls.astype(int)\n",
      "    v = (2*NW-1) #approximate degrees of freedom\n",
      "    \n",
      "    if np.remainder(max(y.shape), 2) == 1:\n",
      "        pls = pls[0:pls.shape[0] - 1]\n",
      "        \n",
      "    #Compute the discrete prolate spheroidal sequences, requires lbtfr.\n",
      "    E, V = dpss(N, NW, k) \n",
      "    \n",
      "    #Compute the windowed DFTs.\n",
      "    fkx = np.fft.fft(E[0:k,:]*np.outer(np.ones(shape=(k)),x),N)\n",
      "    fky = np.fft.fft(E[0:k,:]*np.outer(np.ones(shape=(k)),y),N)\n",
      "    \n",
      "    Pkx = abs(fkx) ** 2\n",
      "    Pky = abs(fky) ** 2\n",
      "    \n",
      "    #Iteration to determine adaptive weights:    \n",
      "    for i1 in range(1, 3):\n",
      "        if i1 == 1:\n",
      "            vari = np.sum(x*x)/N        \n",
      "            Pk = Pkx        \n",
      "        if i1 == 2:\n",
      "            vari = np.sum(y*y)/N\n",
      "            Pk = Pky        \n",
      "        P = (Pk[0, :] + Pk[1, :]) / 2\n",
      "        \n",
      "        # initial spectrum estimate\n",
      "        Ptemp = np.zeros(shape=(1, N), dtype='float64')\n",
      "        P1 = np.zeros(shape=(1,N), dtype='float64')\n",
      "        tol = (0.0005*vari) / N\n",
      "        \n",
      "        # usually within 'tol'erance in about three iterations, see equations from [2] (P&W pp 368-370).   \n",
      "        a = vari* (1 - V)\n",
      "        \n",
      "        while np.sum(abs(P - P1) / N) > tol:        \n",
      "            b=(np.outer(np.ones(shape=(1,k)),P))/(np.outer(V,P)+np.outer(a,np.ones(shape=(1,N)))) # weights        \n",
      "            wk =(b**2)*(np.outer(V,np.ones(shape=(N,1)))) # new spectral estimate        \n",
      "            P1 = np.sum(wk*Pk, axis=0)/np.sum(wk,axis=0)        \n",
      "            Ptemp = P1; P1 = P; P = Ptemp # swap P and P1        \n",
      "    \n",
      "        if i1 == 1:\n",
      "            fkx = np.sqrt(k)*sqrt(wk)*fkx / kron(ones((k,1)),np.sum(sqrt(wk))) \n",
      "            Fx = P #Power density spectral estimate of x        \n",
      "            \n",
      "        if i1 == 2:\n",
      "            fky = sqrt(k)*sqrt(wk)*fky / kron(ones((k,1)),np.sum(sqrt(wk)))         \n",
      "            Fy = P #Power density spectral estimate of y\n",
      "    \n",
      "    #As a check, the quantity sum(abs(fkx(pls,:))'.^2) is the same as Fx and\n",
      "    #the spectral estimate from pmtmPH.\n",
      "    \n",
      "    #Compute the cross spectrum, phase delay and coherence\n",
      "    Cxy = np.sum(fkx*fky.conjugate(),axis=0)\n",
      "    ph = np.angle(Cxy)#*180/np.pi#deg=1)\n",
      "    c = abs(Cxy) / sqrt(sum(abs(fkx)**2, axis=0) * sum(abs(fky)**2,axis=0))\n",
      "    \n",
      "    # if qbias ==1, correct coherence estimate for bias\n",
      "    if qbias==1:\n",
      "        c=cohbias(v,c)\n",
      "    \n",
      "    # confn is the number of iterations to use in estimating phase uncertainty via Monte Carlo analysis\n",
      "    if confn >1:    \n",
      "        cb=cohbias(v,c) # correct for bias\n",
      "        \n",
      "        #ciph = np.zeros((confn,len(pls)))\n",
      "        phi = np.zeros((confn,len(pls)))\n",
      "        \n",
      "        for i in xrange(confn):\n",
      "            # create semi-random timeseries using coherence estimate\n",
      "            fx = np.fft.fft(np.random.randn(len(x))+1)\n",
      "            fx = fx/sum(abs(fx))\n",
      "            \n",
      "            fy = np.fft.fft(np.random.randn(len(y))+1)\n",
      "            fy = fy/sum(abs(fy))  \n",
      "            \n",
      "            ys = real(np.fft.ifft(fy * np.sqrt(1 - cb ** 2))) \n",
      "            ys = ys + real(np.fft.ifft(fx *cb))\n",
      "            \n",
      "            xs = real(np.fft.ifft(fx))\n",
      "            # use xs and ys as input for function to determine coherence and phase\n",
      "            si, ciph,phi[i], phi_ignore,xx_ignor,yy_ignore,xy_ignore = cmtm(xs,ys,dt,NW)\n",
      "        \n",
      "        # sort and average the highest uncertianties\n",
      "        pl = int(round(0.975*i+1))\n",
      "        phi = sort(phi,axis=0)        \n",
      "        phi = phi[((i+1)-pl):pl]\n",
      "        phi = np.array([phi[pl-1,:],-phi[pl-confn,:]])\n",
      "        phi = phi.mean(axis=0)#\n",
      "        phi = np.convolve(phi, np.array([1,1,1])/3)\n",
      "        phi = phi[1:-1]\n",
      "        \n",
      "    # Cut to one-sided functions\n",
      "    Fx = Fx[pls]\n",
      "    Fy = Fy[pls]\n",
      "    Cxy = Cxy[pls]\n",
      "    c = c[pls]\n",
      "    s = s[pls]\n",
      "    ph = ph[pls]\n",
      "    \n",
      "    try:\n",
      "        phi = phi*1        \n",
      "    except NameError:        \n",
      "        phi = np.zeros_like(pls)        \n",
      "    \n",
      "    # Function returns: frequency (s), coherence (c), phase (ph), phase uncertainty (phi), \n",
      "    #                   power spectrum x (Fx), power spectrum y (Fy), cross spectrum (Cxy)\n",
      "    return s,c,ph,phi,Fx,Fy,Cxy \n",
      "\n",
      "# <codecell>\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pth2 = r'D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\NDVI_2009\\split_rasters\\0//'\n",
      "paths2 = pth2\n",
      "pixelcolumn = 0#j\n",
      "pixelrow = 0#k\n",
      "\n",
      "# Get values for precipitation based on cumper \n",
      "# And only update values for NDVI with a new pixel\n",
      "s_org2 = getvalues(paths2, pixelcolumn, pixelrow, wildcard='IM')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s_org2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "2009-01-01   -0.001038\n",
        "2009-01-02    0.002636\n",
        "2009-01-03    0.006390\n",
        "2009-01-04    0.010264\n",
        "2009-01-05    0.014537\n",
        "2009-01-06    0.019129\n",
        "2009-01-07    0.023922\n",
        "2009-01-08    0.028674\n",
        "2009-01-09    0.033946\n",
        "2009-01-10    0.039177\n",
        "2009-01-11    0.044928\n",
        "2009-01-12    0.050320\n",
        "2009-01-13    0.056150\n",
        "2009-01-14    0.062061\n",
        "2009-01-15    0.068011\n",
        "...\n",
        "2009-12-17    0.202436\n",
        "2009-12-18    0.202716\n",
        "2009-12-19    0.202716\n",
        "2009-12-20    0.203235\n",
        "2009-12-21    0.203794\n",
        "2009-12-22    0.204473\n",
        "2009-12-23    0.205791\n",
        "2009-12-24    0.207029\n",
        "2009-12-25    0.208387\n",
        "2009-12-26    0.210144\n",
        "2009-12-27    0.212101\n",
        "2009-12-28    0.214457\n",
        "2009-12-29    0.216893\n",
        "2009-12-30    0.219728\n",
        "2009-12-31    0.222644\n",
        "Length: 364, dtype: float64"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mth = [0.5, 1, 2, 3, 4, 5]\n",
      "prd = [10, 15, 20, 15]#[15, 30, 60, 90, 120, 150]\n",
      "#pth1 = r'D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\TRMM2_2009\\XX_Day_Period\\XX_DaySums_StdNormAnomalyRes'# removed 'NormTypeII'\n",
      "pth1 = r'D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\TRMM2_2009\\10_Day_Period\\split_rasters\\0'\n",
      "#pth2 = r'D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\NDVI_2009\\DaySums_StdNormAnomaly'# #Res, removed 'NormTypeII'\n",
      "pth2 = r'D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\NDVI_2009\\split_rasters\\0'\n",
      "\n",
      "#pixelcolumn = 23 # extract from rasterXSize (0:62) horizontal latitude - whatever\n",
      "#pixelrow = 21 # extract from rasterYSize (0:36) vertical longitude \n",
      "#folderp1 = r'D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\PLOT_CHARTS_2009\\COHERENCE2\\p5//'\n",
      "#folderp2 = r'D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\PLOT_CHARTS_2009\\COHERENCE2\\p4//'\n",
      "\n",
      "#frequency bands of interest (12, 6, 4, 3 months)\n",
      "annual_p = (1./(366+3))\n",
      "annual_m = (1./(366-3))\n",
      "binual_p = (1./((366.+3)/2))\n",
      "binual_m = (1./((366.-3)/2))\n",
      "trinual_p = (1./((366.+3)/3))\n",
      "trinual_m = (1./((366.-3)/3))\n",
      "quatro_p = (1./((366.+3)/4))\n",
      "quatro_m = (1./((366.-3)/4))\n",
      "\n",
      "ph = pth2+'//0_NDVI_IM_2009001.TIF'\n",
      "ds = gdal.Open(ph)\n",
      "base = ds.ReadAsArray()\n",
      "\n",
      "for i in range(0,1):#6\n",
      "    \n",
      "    coher_array12 = np.zeros_like(base)\n",
      "    coher_array06 = np.zeros_like(base)\n",
      "    coher_array04 = np.zeros_like(base)\n",
      "    coher_array03 = np.zeros_like(base)\n",
      "    \n",
      "    phase_array12 = np.zeros_like(base)\n",
      "    phase_array06 = np.zeros_like(base)\n",
      "    phase_array04 = np.zeros_like(base)\n",
      "    phase_array03 = np.zeros_like(base)\n",
      "    \n",
      "    phunc_array12 = np.zeros_like(base)\n",
      "    phunc_array06 = np.zeros_like(base)\n",
      "    phunc_array04 = np.zeros_like(base)\n",
      "    phunc_array03 = np.zeros_like(base)\n",
      "    \n",
      "    pwsdx_array12 = np.zeros_like(base)\n",
      "    pwsdx_array06 = np.zeros_like(base)\n",
      "    pwsdx_array04 = np.zeros_like(base)\n",
      "    pwsdx_array03 = np.zeros_like(base)\n",
      "\n",
      "    pwsdy_array12 = np.zeros_like(base)\n",
      "    pwsdy_array06 = np.zeros_like(base)\n",
      "    pwsdy_array04 = np.zeros_like(base)\n",
      "    pwsdy_array03 = np.zeros_like(base)\n",
      "\n",
      "    csdxy_array12 = np.zeros_like(base)\n",
      "    csdxy_array06 = np.zeros_like(base)\n",
      "    csdxy_array04 = np.zeros_like(base)\n",
      "    csdxy_array03 = np.zeros_like(base)\n",
      "    \n",
      "    for j in range(0, 1194): # 0,48 pixelcolumn\n",
      "        for k in range(0,876): #0,35 pixelrow\n",
      "        \n",
      "            # Set path for cumulative period of precipitation\n",
      "            # And corresponding period time\n",
      "            #cumper = mth[i]\n",
      "            #period = prd[i]            \n",
      "            #paths1 = pth1.replace('XX', str(period))\n",
      "            paths1 = pth1\n",
      "            paths2 = pth2\n",
      "            \n",
      "    \n",
      "            # Set pixelvalues\n",
      "            # TODO: Implementation to read row by row or all-in-one\n",
      "            pixelcolumn = j\n",
      "            pixelrow = k\n",
      "            \n",
      "            # Get values for precipitation based on cumper \n",
      "            # And only update values for NDVI with a new pixel\n",
      "            s_org2 = getvalues(paths2, pixelcolumn, pixelrow, wildcard='IM')            \n",
      "            if s_org2.mean()<>-99999.0:\n",
      "                s_org1 = getvalues(paths1, pixelcolumn, pixelrow, wildcard='TRMM')                \n",
      "            \n",
      "                # Create dataframe from the two series and apply an outer join            \n",
      "                df1 = pd.DataFrame(s_org1, columns=['prcp'])\n",
      "                df2 = pd.DataFrame(s_org2, columns=['ndvi'])            \n",
      "                df = pd.concat([df1, df2], join='outer', axis=1)\n",
      "                \n",
      "                # Before splitting the signals, first drop eventual NaN values\n",
      "                df = df.dropna()            \n",
      "                s1 = df['prcp']\n",
      "                s2 = df['ndvi']\n",
      "                \n",
      "                sf,cf,phf,phif,fxf,fyf,cxyf = cmtm(np.resize(s1, (s1.size*50) ), np.resize(s2, (s2.size*50) ), qbias=1, confn=0)\n",
      "\n",
      "                # select frequencies\n",
      "                sf12 = sf[(annual_p < sf) & (sf < annual_m)].mean()\n",
      "                sf06 = sf[(binual_p < sf) & (sf < binual_m)].mean()\n",
      "                sf04 = sf[(trinual_p < sf) & (sf < trinual_m)].mean()\n",
      "                sf03 = sf[(quatro_p < sf) & (sf < quatro_m)].mean()\n",
      "                \n",
      "                # select coherence\n",
      "                cf12 = cf[(annual_p < sf) & (sf < annual_m)].mean()\n",
      "                cf06 = cf[(binual_p < sf) & (sf < binual_m)].mean()\n",
      "                cf04 = cf[(trinual_p < sf) & (sf < trinual_m)].mean()\n",
      "                cf03 = cf[(quatro_p < sf) & (sf < quatro_m)].mean()\n",
      "                \n",
      "                # select phase-delay (convert to days)\n",
      "                phf12 = phf[(annual_p < sf) & (sf < annual_m)].mean()\n",
      "                phf12 = phf12/(2*np.pi*sf12)\n",
      "                if phf12 < 0:\n",
      "                    phf12 = phf12 +(1/sf12)\n",
      "                    \n",
      "                phf06 = phf[(binual_p < sf) & (sf < binual_m)].mean()\n",
      "                phf06 = phf06/(2*np.pi*sf06)\n",
      "                if phf06 < 0:\n",
      "                    phf06 = phf06 +(1/sf06)                \n",
      "                    \n",
      "                phf04 = phf[(trinual_p < sf) & (sf < trinual_m)].mean()\n",
      "                phf04 = phf04/(2*np.pi*sf04)\n",
      "                if phf04 < 0:\n",
      "                    phf04 = phf04 +(1/sf04)\n",
      "                    \n",
      "                phf03 = phf[(quatro_p < sf) & (sf < quatro_m)].mean()\n",
      "                phf03 = phf03/(2*np.pi*sf03)\n",
      "                if phf03 < 0:\n",
      "                    phf03 = phf03 +(1/sf03)                                \n",
      "                \n",
      "                # select phase uncertainty via monte carlo (convert to days) convert from -pi/pi to 0 and 2pi period\n",
      "                phif12 = phif[(annual_p < sf) & (sf < annual_m)].mean()\n",
      "                phif12 = phif12/(2*np.pi*sf12)\n",
      "                    \n",
      "                phif06 = phif[(binual_p < sf) & (sf < binual_m)].mean()\n",
      "                phif06 = phif06/(2*np.pi*sf06)\n",
      "                    \n",
      "                phif04 = phif[(trinual_p < sf) & (sf < trinual_m)].mean()\n",
      "                phif04 = phif04/(2*np.pi*sf04)\n",
      "                    \n",
      "                phif03 = phif[(quatro_p < sf) & (sf < quatro_m)].mean()\n",
      "                phif03 = phif03/(2*np.pi*sf03)\n",
      "\n",
      "                \n",
      "                # select power spectrum x\n",
      "                fxf12 = real(fxf[(annual_p < sf) & (sf < annual_m)]).mean()\n",
      "                fxf06 = real(fxf[(binual_p < sf) & (sf < binual_m)]).mean()\n",
      "                fxf04 = real(fxf[(trinual_p < sf) & (sf < trinual_m)]).mean()\n",
      "                fxf03 = real(fxf[(quatro_p < sf) & (sf < quatro_m)]).mean()\n",
      "                \n",
      "                # select power spectrum y\n",
      "                fyf12 = real(fyf[(annual_p < sf) & (sf < annual_m)]).mean()\n",
      "                fyf06 = real(fyf[(binual_p < sf) & (sf < binual_m)]).mean()\n",
      "                fyf04 = real(fyf[(trinual_p < sf) & (sf < trinual_m)]).mean()\n",
      "                fyf03 = real(fyf[(quatro_p < sf) & (sf < quatro_m)]).mean()\n",
      "                \n",
      "                # select cross spectrum xy\n",
      "                cxyf12 = real(cxyf[(annual_p < sf) & (sf < annual_m)]).mean()\n",
      "                cxyf06 = real(cxyf[(binual_p < sf) & (sf < binual_m)]).mean()\n",
      "                cxyf04 = real(cxyf[(trinual_p < sf) & (sf < trinual_m)]).mean()\n",
      "                cxyf03 = real(cxyf[(quatro_p < sf) & (sf < quatro_m)]).mean()\n",
      "\n",
      "                # set raster values\n",
      "                coher_array12[k][j] = cf12\n",
      "                coher_array06[k][j] = cf06\n",
      "                coher_array04[k][j] = cf04\n",
      "                coher_array03[k][j] = cf03\n",
      "                \n",
      "                phase_array12[k][j] = phf12\n",
      "                phase_array06[k][j] = phf06\n",
      "                phase_array04[k][j] = phf04\n",
      "                phase_array03[k][j] = phf03\n",
      "                \n",
      "                phunc_array12[k][j] = phif12\n",
      "                phunc_array06[k][j] = phif06\n",
      "                phunc_array04[k][j] = phif04\n",
      "                phunc_array03[k][j] = phif03\n",
      "                \n",
      "                pwsdx_array12[k][j] = fxf12\n",
      "                pwsdx_array06[k][j] = fxf06\n",
      "                pwsdx_array04[k][j] = fxf04\n",
      "                pwsdx_array03[k][j] = fxf03\n",
      "            \n",
      "                pwsdy_array12[k][j] = fyf12\n",
      "                pwsdy_array06[k][j] = fyf06\n",
      "                pwsdy_array04[k][j] = fyf04\n",
      "                pwsdy_array03[k][j] = fyf03\n",
      "            \n",
      "                csdxy_array12[k][j] = cxyf12\n",
      "                csdxy_array06[k][j] = cxyf06\n",
      "                csdxy_array04[k][j] = cxyf04\n",
      "                csdxy_array03[k][j] = cxyf03\n",
      "\n",
      "            else:\n",
      "                # set raster values if no s1 or s2\n",
      "                coher_array12[k][j] = -99999.0\n",
      "                coher_array06[k][j] = -99999.0\n",
      "                coher_array04[k][j] = -99999.0\n",
      "                coher_array03[k][j] = -99999.0\n",
      "                \n",
      "                phase_array12[k][j] = -99999.0\n",
      "                phase_array06[k][j] = -99999.0\n",
      "                phase_array04[k][j] = -99999.0\n",
      "                phase_array03[k][j] = -99999.0\n",
      "                \n",
      "                phunc_array12[k][j] = -99999.0\n",
      "                phunc_array06[k][j] = -99999.0\n",
      "                phunc_array04[k][j] = -99999.0\n",
      "                phunc_array03[k][j] = -99999.0\n",
      "                \n",
      "                pwsdx_array12[k][j] = -99999.0\n",
      "                pwsdx_array06[k][j] = -99999.0\n",
      "                pwsdx_array04[k][j] = -99999.0\n",
      "                pwsdx_array03[k][j] = -99999.0\n",
      "            \n",
      "                pwsdy_array12[k][j] = -99999.0\n",
      "                pwsdy_array06[k][j] = -99999.0\n",
      "                pwsdy_array04[k][j] = -99999.0\n",
      "                pwsdy_array03[k][j] = -99999.0\n",
      "            \n",
      "                csdxy_array12[k][j] = -99999.0\n",
      "                csdxy_array06[k][j] = -99999.0\n",
      "                csdxy_array04[k][j] = -99999.0\n",
      "                csdxy_array03[k][j] = -99999.0\n",
      "                \n",
      "            print 'Col',j,'Row', k, 'CumPer', i, 'Phase',phase_array12[k][j], 'Coherence', coher_array12[k][j]\n",
      "                \n",
      "            \n",
      "    folder12 = r'D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\PLOT_MAPS_2009\\date_23042014\\0\\12//'\n",
      "    path_coher12 = folder12+'coher12_'+str(prd[i])+'.tif'\n",
      "    path_phase12 = folder12+'phase12_'+str(prd[i])+'.tif'\n",
      "    path_phunc12 = folder12+'phunc12_'+str(prd[i])+'.tif'\n",
      "    path_pwsdx12 = folder12+'pwsdx12_'+str(prd[i])+'.tif'\n",
      "    path_pwsdy12 = folder12+'pwsdy12_'+str(prd[i])+'.tif'\n",
      "    path_csdxy12 = folder12+'csdxy12_'+str(prd[i])+'.tif'\n",
      "\n",
      "    folder06 = r'D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\PLOT_MAPS_2009\\date_23042014\\0\\6//'\n",
      "    path_coher06 = folder06+'coher06_'+str(prd[i])+'.tif'\n",
      "    path_phase06 = folder06+'phase06_'+str(prd[i])+'.tif'\n",
      "    path_phunc06 = folder06+'phunc06_'+str(prd[i])+'.tif'\n",
      "    path_pwsdx06 = folder06+'pwsdx06_'+str(prd[i])+'.tif'\n",
      "    path_pwsdy06 = folder06+'pwsdy06_'+str(prd[i])+'.tif'\n",
      "    path_csdxy06 = folder06+'csdxy06_'+str(prd[i])+'.tif'\n",
      "\n",
      "    folder04 = r'D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\PLOT_MAPS_2009\\date_23042014\\0\\4//'\n",
      "    path_coher04 = folder04+'coher04_'+str(prd[i])+'.tif'\n",
      "    path_phase04 = folder04+'phase04_'+str(prd[i])+'.tif'\n",
      "    path_phunc04 = folder04+'phunc04_'+str(prd[i])+'.tif'\n",
      "    path_pwsdx04 = folder04+'pwsdx04_'+str(prd[i])+'.tif'\n",
      "    path_pwsdy04 = folder04+'pwsdy04_'+str(prd[i])+'.tif'\n",
      "    path_csdxy04 = folder04+'csdxy04_'+str(prd[i])+'.tif'\n",
      "\n",
      "    folder03 = r'D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\PLOT_MAPS_2009\\date_23042014\\0\\3//'\n",
      "    path_coher03 = folder03+'coher03_'+str(prd[i])+'.tif'\n",
      "    path_phase03 = folder03+'phase03_'+str(prd[i])+'.tif'\n",
      "    path_phunc03 = folder03+'phunc03_'+str(prd[i])+'.tif'\n",
      "    path_pwsdx03 = folder03+'pwsdx03_'+str(prd[i])+'.tif'\n",
      "    path_pwsdy03 = folder03+'pwsdy03_'+str(prd[i])+'.tif'\n",
      "    path_csdxy03 = folder03+'csdxy03_'+str(prd[i])+'.tif'\n",
      "\n",
      "    #path_rmse = folder+'rmse_'+str(prd[i])+'.tif'\n",
      "\n",
      "    saveRaster(path_coher12, coher_array12, ds, datatype=6, nan=-99999.0)\n",
      "    saveRaster(path_phase12, phase_array12, ds, datatype=6, nan=-99999.0)\n",
      "    saveRaster(path_phunc12, phunc_array12, ds, datatype=6, nan=-99999.0)\n",
      "    saveRaster(path_pwsdx12, pwsdx_array12, ds, datatype=6, nan=-99999.0)\n",
      "    saveRaster(path_pwsdy12, pwsdy_array12, ds, datatype=6, nan=-99999.0)\n",
      "    saveRaster(path_csdxy12, csdxy_array12, ds, datatype=6, nan=-99999.0)\n",
      "\n",
      "    saveRaster(path_coher06, coher_array06, ds, datatype=6, nan=-99999.0)\n",
      "    saveRaster(path_phase06, phase_array06, ds, datatype=6, nan=-99999.0)\n",
      "    saveRaster(path_phunc06, phunc_array06, ds, datatype=6, nan=-99999.0)\n",
      "    saveRaster(path_pwsdx06, pwsdx_array06, ds, datatype=6, nan=-99999.0)\n",
      "    saveRaster(path_pwsdy06, pwsdy_array06, ds, datatype=6, nan=-99999.0)\n",
      "    saveRaster(path_csdxy06, csdxy_array06, ds, datatype=6, nan=-99999.0)\n",
      "\n",
      "    saveRaster(path_coher04, coher_array04, ds, datatype=6, nan=-99999.0)\n",
      "    saveRaster(path_phase04, phase_array04, ds, datatype=6, nan=-99999.0)\n",
      "    saveRaster(path_phunc04, phunc_array04, ds, datatype=6, nan=-99999.0)\n",
      "    saveRaster(path_pwsdx04, pwsdx_array04, ds, datatype=6, nan=-99999.0)\n",
      "    saveRaster(path_pwsdy04, pwsdy_array04, ds, datatype=6, nan=-99999.0)\n",
      "    saveRaster(path_csdxy04, csdxy_array04, ds, datatype=6, nan=-99999.0)\n",
      "    \n",
      "    saveRaster(path_coher03, coher_array03, ds, datatype=6, nan=-99999.0)\n",
      "    saveRaster(path_phase03, phase_array03, ds, datatype=6, nan=-99999.0)\n",
      "    saveRaster(path_phunc03, phunc_array03, ds, datatype=6, nan=-99999.0)\n",
      "    saveRaster(path_pwsdx03, pwsdx_array03, ds, datatype=6, nan=-99999.0)\n",
      "    saveRaster(path_pwsdy03, pwsdy_array03, ds, datatype=6, nan=-99999.0)\n",
      "    saveRaster(path_csdxy03, csdxy_array03, ds, datatype=6, nan=-99999.0)\n",
      "\n",
      "    #saveRaster(path_coher, coher_array, ds, datatype=6, nan=-99999.0)\n",
      "    #saveRaster(path_rmse, rmse_array, ds, datatype=6, nan=-99999.0)\n",
      "    \n",
      "    print path_phase12\n",
      "    print path_coher12\n",
      "    #print path_rmse                \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}