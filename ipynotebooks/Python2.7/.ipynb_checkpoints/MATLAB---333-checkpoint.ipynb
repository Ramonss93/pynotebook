{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pymat2\n",
      "import os\n",
      "import pandas as pd\n",
      "from osgeo import gdal\n",
      "import numpy as np\n",
      "import datetime\n",
      "import matplotlib.pyplot as plt\n",
      "from scipy.signal import detrend as sp_detrend\n",
      "import matplotlib.gridspec as gridspec\n",
      "import matplotlib.pyplot as pl\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import scipy.signal as sig\n",
      "import scipy.stats.distributions as dist\n",
      "\n",
      "import nitime.algorithms as tsa\n",
      "import nitime.utils as utils\n",
      "from nitime.viz import winspect\n",
      "from nitime.viz import plot_spectral_estimate\n",
      "\n",
      "import datetime\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib as mpl\n",
      "import sys, os, re\n",
      "from scipy import stats\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "D:\\Python27\\lib\\site-packages\\matplotlib\\cbook.py:122: MatplotlibDeprecationWarning: The matplotlib.mpl module was deprecated in version 1.3. Use `import matplotlib as mpl` instead.\n",
        "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def saveRaster(path, array, dsSource, datatype=3, formatraster=\"GTiff\", nan=None): \n",
      "    \"\"\"\n",
      "    Datatypes:\n",
      "    unknown = 0\n",
      "    byte = 1\n",
      "    unsigned int16 = 2\n",
      "    signed int16 = 3\n",
      "    unsigned int32 = 4\n",
      "    signed int32 = 5\n",
      "    float32 = 6\n",
      "    float64 = 7\n",
      "    complex int16 = 8\n",
      "    complex int32 = 9\n",
      "    complex float32 = 10\n",
      "    complex float64 = 11\n",
      "    float32 = 6, \n",
      "    signed int = 3\n",
      "    \n",
      "    Formatraster:\n",
      "    GeoTIFF = GTiff\n",
      "    Erdas = HFA (output = .img)\n",
      "    OGC web map service = WMS\n",
      "    png = PNG\n",
      "    \"\"\"\n",
      "    # Set Driver\n",
      "    format_ = formatraster #save as format\n",
      "    driver = gdal.GetDriverByName( format_ )\n",
      "    driver.Register()\n",
      "    \n",
      "    # Set Metadata for Raster output\n",
      "    cols = dsSource.RasterXSize\n",
      "    rows = dsSource.RasterYSize\n",
      "    bands = dsSource.RasterCount\n",
      "    datatype = datatype#band.DataType\n",
      "    \n",
      "    # Set Projection for Raster\n",
      "    outDataset = driver.Create(path, cols, rows, bands, datatype)\n",
      "    geoTransform = dsSource.GetGeoTransform()\n",
      "    outDataset.SetGeoTransform(geoTransform)\n",
      "    proj = dsSource.GetProjection()\n",
      "    outDataset.SetProjection(proj)\n",
      "    \n",
      "    # Write output to band 1 of new Raster and write NaN value\n",
      "    outBand = outDataset.GetRasterBand(1)\n",
      "    if nan != None:\n",
      "        outBand.SetNoDataValue(nan)\n",
      "    outBand.WriteArray(array) #save input array\n",
      "    #outBand.WriteArray(dem)\n",
      "    \n",
      "    # Close and finalise newly created Raster\n",
      "    #F_M01 = None\n",
      "    outBand = None\n",
      "    proj = None\n",
      "    geoTransform = None\n",
      "    outDataset = None\n",
      "    driver = None\n",
      "    datatype = None\n",
      "    bands = None\n",
      "    rows = None\n",
      "    cols = None\n",
      "    driver = None\n",
      "    array = None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Colors via http://colorbrewer2.com/\n",
      "WHITE, LIGHT_GRAY, GRAY, BLACK = [ \"#FFFFFF\", \"#E5E5E5\", \"#777777\", \"#000000\" ] \n",
      "COLORS = [ \"#2C7BB6\", \"#FF6600\", \"#660099\", \"#D7191C\", \"#FFFFBF\", \"#ABD9E9\"]\n",
      "BLUE, ORANGE, PURPLE, RED, YELLOW, LIGHT_BLUE = COLORS\n",
      "HIGH_ALPHA = 0.9\n",
      "MEDIUM_ALPHA = 0.5\n",
      "LOW_ALPHA = 0.1\n",
      "rgba = mpl.colors.colorConverter.to_rgba\n",
      "\n",
      "def set_styles(style_dict):\n",
      "    \"\"\"Set matplotlib styles from nested a nested dictionary\"\"\"\n",
      "    for obj in style_dict: mpl.rc(obj, **style_dict[obj]) \n",
      "\n",
      "set_styles({\n",
      "    \"figure\": { \"figsize\": [ 12, 4 ], \"facecolor\": WHITE },\n",
      "    \"savefig\": { \"dpi\": 200, \"bbox\": \"tight\" },\n",
      "    \"patch\": { \"linewidth\": 0.5, \"facecolor\": ORANGE, \"edgecolor\": WHITE, \"antialiased\": True },\n",
      "    \"font\": { \"size\": 8 },\n",
      "    \"legend\": { \"fontsize\": 10 },\n",
      "    \"axes\": { \n",
      "        \"facecolor\": LIGHT_GRAY, \n",
      "        \"edgecolor\": WHITE, \n",
      "        \"linewidth\": 1, \n",
      "        \"grid\": True, \n",
      "        \"titlesize\": \"large\", \n",
      "        \"labelsize\": \"large\", \n",
      "        \"labelcolor\": BLACK,\n",
      "        \"axisbelow\": True,\n",
      "        \"color_cycle\": COLORS\n",
      "    },\n",
      "    \"xtick\": { \"color\": GRAY, \"direction\": \"out\" }, #GRAY\n",
      "    \"ytick\": { \"color\": GRAY, \"direction\": \"out\" }, #GRAY\n",
      "    \"grid\": { \"color\": WHITE, \"linestyle\": \"-\" }\n",
      "})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def savitzky_golay(y, window_size, order, deriv=0, rate=1):\n",
      "    r\"\"\"Smooth (and optionally differentiate) data with a Savitzky-Golay filter.\n",
      "    The Savitzky-Golay filter removes high frequency noise from data.\n",
      "    It has the advantage of preserving the original shape and\n",
      "    features of the signal better than other types of filtering\n",
      "    approaches, such as moving averages techniques.\n",
      "    Parameters\n",
      "    ----------\n",
      "    y : array_like, shape (N,)\n",
      "        the values of the time history of the signal.\n",
      "    window_size : int\n",
      "        the length of the window. Must be an odd integer number.\n",
      "    order : int\n",
      "        the order of the polynomial used in the filtering.\n",
      "        Must be less then `window_size` - 1.\n",
      "    deriv: int\n",
      "        the order of the derivative to compute (default = 0 means only smoothing)\n",
      "    Returns\n",
      "    -------\n",
      "    ys : ndarray, shape (N)\n",
      "        the smoothed signal (or it's n-th derivative).\n",
      "    Notes\n",
      "    -----\n",
      "    The Savitzky-Golay is a type of low-pass filter, particularly\n",
      "    suited for smoothing noisy data. The main idea behind this\n",
      "    approach is to make for each point a least-square fit with a\n",
      "    polynomial of high order over a odd-sized window centered at\n",
      "    the point.\n",
      "    Examples\n",
      "    --------\n",
      "    t = np.linspace(-4, 4, 500)\n",
      "    y = np.exp( -t**2 ) + np.random.normal(0, 0.05, t.shape)\n",
      "    ysg = savitzky_golay(y, window_size=31, order=4)\n",
      "    import matplotlib.pyplot as plt\n",
      "    plt.plot(t, y, label='Noisy signal')\n",
      "    plt.plot(t, np.exp(-t**2), 'k', lw=1.5, label='Original signal')\n",
      "    plt.plot(t, ysg, 'r', label='Filtered signal')\n",
      "    plt.legend()\n",
      "    plt.show()\n",
      "    References\n",
      "    ----------\n",
      "    .. [1] A. Savitzky, M. J. E. Golay, Smoothing and Differentiation of\n",
      "       Data by Simplified Least Squares Procedures. Analytical\n",
      "       Chemistry, 1964, 36 (8), pp 1627-1639.\n",
      "    .. [2] Numerical Recipes 3rd Edition: The Art of Scientific Computing\n",
      "       W.H. Press, S.A. Teukolsky, W.T. Vetterling, B.P. Flannery\n",
      "       Cambridge University Press ISBN-13: 9780521880688\n",
      "    \"\"\"\n",
      "    import numpy as np\n",
      "    from math import factorial\n",
      "\n",
      "    try:\n",
      "        window_size = np.abs(np.int(window_size))\n",
      "        order = np.abs(np.int(order))\n",
      "    except ValueError as msg:\n",
      "        raise ValueError(\"window_size and order have to be of type int\")\n",
      "    if window_size % 2 != 1 or window_size < 1:\n",
      "        raise TypeError(\"window_size size must be a positive odd number\")\n",
      "    if window_size < order + 2:\n",
      "        raise TypeError(\"window_size is too small for the polynomials order\")\n",
      "    order_range = range(order+1)\n",
      "    half_window = (window_size -1) // 2\n",
      "    # precompute coefficients\n",
      "    b = np.mat([[k**i for i in order_range] for k in range(-half_window, half_window+1)])\n",
      "    m = np.linalg.pinv(b).A[deriv] * rate**deriv * factorial(deriv)\n",
      "    # pad the signal at the extremes with\n",
      "    # values taken from the signal itself\n",
      "    firstvals = y[0] - np.abs( y[1:half_window+1][::-1] - y[0] )\n",
      "    lastvals = y[-1] + np.abs(y[-half_window-1:-1][::-1] - y[-1])\n",
      "    y = np.concatenate((firstvals, y, lastvals))\n",
      "    return np.convolve( m[::-1], y, mode='valid')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def _datacheck_peakdetect(x_axis, y_axis):\n",
      "    if x_axis is None:\n",
      "        x_axis = range(len(y_axis))\n",
      "    \n",
      "    if len(y_axis) != len(x_axis):\n",
      "        raise (ValueError, \n",
      "                'Input vectors y_axis and x_axis must have same length')\n",
      "    \n",
      "    #needs to be a numpy array\n",
      "    y_axis = np.array(y_axis)\n",
      "    x_axis = np.array(x_axis)\n",
      "    return x_axis, y_axis"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def peakdetect(y_axis, x_axis = None, lookahead = 300, delta=0):\n",
      "    \"\"\"\n",
      "    Converted from/based on a MATLAB script at: \n",
      "    http://billauer.co.il/peakdet.html\n",
      "    \n",
      "    function for detecting local maximas and minmias in a signal.\n",
      "    Discovers peaks by searching for values which are surrounded by lower\n",
      "    or larger values for maximas and minimas respectively\n",
      "    \n",
      "    keyword arguments:\n",
      "    y_axis -- A list containg the signal over which to find peaks\n",
      "    x_axis -- (optional) A x-axis whose values correspond to the y_axis list\n",
      "        and is used in the return to specify the postion of the peaks. If\n",
      "        omitted an index of the y_axis is used. (default: None)\n",
      "    lookahead -- (optional) distance to look ahead from a peak candidate to\n",
      "        determine if it is the actual peak (default: 200) \n",
      "        '(sample / period) / f' where '4 >= f >= 1.25' might be a good value\n",
      "    delta -- (optional) this specifies a minimum difference between a peak and\n",
      "        the following points, before a peak may be considered a peak. Useful\n",
      "        to hinder the function from picking up false peaks towards to end of\n",
      "        the signal. To work well delta should be set to delta >= RMSnoise * 5.\n",
      "        (default: 0)\n",
      "            delta function causes a 20% decrease in speed, when omitted\n",
      "            Correctly used it can double the speed of the function\n",
      "    \n",
      "    return -- two lists [max_peaks, min_peaks] containing the positive and\n",
      "        negative peaks respectively. Each cell of the lists contains a tupple\n",
      "        of: (position, peak_value) \n",
      "        to get the average peak value do: np.mean(max_peaks, 0)[1] on the\n",
      "        results to unpack one of the lists into x, y coordinates do: \n",
      "        x, y = zip(*tab)\n",
      "    \"\"\"\n",
      "    max_peaks = []\n",
      "    min_peaks = []\n",
      "    dump = []   #Used to pop the first hit which almost always is false\n",
      "       \n",
      "    # check input data\n",
      "    x_axis, y_axis = _datacheck_peakdetect(x_axis, y_axis)\n",
      "    # store data length for later use\n",
      "    length = len(y_axis)\n",
      "    \n",
      "    \n",
      "    #perform some checks\n",
      "    if lookahead < 1:\n",
      "        raise ValueError ( \"Lookahead must be '1' or above in value\")\n",
      "    if not (np.isscalar(delta) and delta >= 0):\n",
      "        raise ValueError ( \"delta must be a positive number\" )\n",
      "    \n",
      "    #maxima and minima candidates are temporarily stored in\n",
      "    #mx and mn respectively\n",
      "    mn, mx = np.Inf, -np.Inf\n",
      "    \n",
      "    #Only detect peak if there is 'lookahead' amount of points after it\n",
      "    for index, (x, y) in enumerate(zip(x_axis[:-lookahead], \n",
      "                                        y_axis[:-lookahead])):\n",
      "        if y > mx:\n",
      "            mx = y\n",
      "            mxpos = x\n",
      "        if y < mn:\n",
      "            mn = y\n",
      "            mnpos = x\n",
      "        \n",
      "        ####look for max####\n",
      "        if y < mx-delta and mx != np.Inf:\n",
      "            #Maxima peak candidate found\n",
      "            #look ahead in signal to ensure that this is a peak and not jitter\n",
      "            if y_axis[index:index+lookahead].max() < mx:\n",
      "                max_peaks.append([mxpos, mx])\n",
      "                dump.append(True)\n",
      "                #set algorithm to only find minima now\n",
      "                mx = np.Inf\n",
      "                mn = np.Inf\n",
      "                if index+lookahead >= length:\n",
      "                    #end is within lookahead no more peaks can be found\n",
      "                    break\n",
      "                continue\n",
      "            #else:  #slows shit down this does\n",
      "            #    mx = ahead\n",
      "            #    mxpos = x_axis[np.where(y_axis[index:index+lookahead]==mx)]\n",
      "        \n",
      "        ####look for min####\n",
      "        if y > mn+delta and mn != -np.Inf:\n",
      "            #Minima peak candidate found \n",
      "            #look ahead in signal to ensure that this is a peak and not jitter\n",
      "            if y_axis[index:index+lookahead].min() > mn:\n",
      "                min_peaks.append([mnpos, mn])\n",
      "                dump.append(False)\n",
      "                #set algorithm to only find maxima now\n",
      "                mn = -np.Inf\n",
      "                mx = -np.Inf\n",
      "                if index+lookahead >= length:\n",
      "                    #end is within lookahead no more peaks can be found\n",
      "                    break\n",
      "            #else:  #slows shit down this does\n",
      "            #    mn = ahead\n",
      "            #    mnpos = x_axis[np.where(y_axis[index:index+lookahead]==mn)]\n",
      "    \n",
      "    \n",
      "    #Remove the false hit on the first value of the y_axis\n",
      "    try:\n",
      "        if dump[0]:\n",
      "            max_peaks.pop(0)\n",
      "        else:\n",
      "            min_peaks.pop(0)\n",
      "        del dump\n",
      "    except IndexError:\n",
      "        #no peaks were found, should the function return empty lists?\n",
      "        pass\n",
      "        \n",
      "    return [max_peaks, min_peaks]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def listall(RootFolder, wildcard=''):\n",
      "    lists = [os.path.join(root, name)    \n",
      "                 for root, dirs, files in os.walk(RootFolder)\n",
      "                   for name in files\n",
      "                   if wildcard in name\n",
      "                     if name.endswith('.tif')]\n",
      "    return lists\n",
      "\n",
      "def getvalues(rootpath, pc, pr, wildcard=''):\n",
      "    \n",
      "    li = []\n",
      "    da = []\n",
      "    i = 0\n",
      "    \n",
      "    #path = r'D:\\Data\\GPCP_30acc_AnnualAcc'\n",
      "    test = listall(rootpath, wildcard)\n",
      "    #test = test[0:-46]\n",
      "    #print (len(test))\n",
      "    #print (test[0])\n",
      "    for t in test:    \n",
      "        raster = gdal.Open(t, gdal.GA_ReadOnly)\n",
      "        nameRas = raster.GetDescription()[-11:-4]\n",
      "        date = datetime.datetime(int(nameRas[0:4]), 1, 1) + datetime.timedelta(int(nameRas[4:9]) - 1) # replaced \"int(nameRas[0:4])\" with \"2010\" first year then add doy\n",
      "        # print date\n",
      "        da.append(date)\n",
      "    \n",
      "        band = raster.GetRasterBand(1)\n",
      "        array = band.ReadAsArray()    \n",
      "        \n",
      "        # print array[879,4142] # Grassland pixel\n",
      "        li.append(array[pr, pc])\n",
      "        \n",
      "        array = None\n",
      "        band = None\n",
      "        raster = None\n",
      "        #print (str(i))\n",
      "        i = i + 1\n",
      "        \n",
      "    signal = pd.Series(data = li, index = da)\n",
      "    return signal"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ml = pymat2.Matlab()\n",
      "ml.start()\n",
      "\n",
      "ml.outputBufferSize = 50000\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ml.restart()\n",
      "ml.eval('x=3*7;x')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "'x =\\n\\n    21\\n\\n'"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import time\n",
      "time.sleep(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mth = [0.5, 1, 2, 3, 4, 5]\n",
      "prd = [15, 30, 60, 90, 120, 150]\n",
      "pth1 = r'D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\TRMM2_2009\\XX_Day_Period\\XX_DaySums_StdNormAnomaly'# removed 'NormTypeII'\n",
      "pth2 = r'D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\NDVI_2009\\DaySums_StdNormAnomalyRes'# removed 'NormTypeII'\n",
      "\n",
      "#pixelcolumn = 23 # extract from rasterXSize (0:62) horizontal latitude - whatever\n",
      "#pixelrow = 21 # extract from rasterYSize (0:36) vertical longitude \n",
      "#folderp1 = r'D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\PLOT_CHARTS_2009\\COHERENCE2\\p5//'\n",
      "#folderp2 = r'D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\PLOT_CHARTS_2009\\COHERENCE2\\p4//'\n",
      "\n",
      "ph = pth2+'//TRMM_CQ_2009001.tif'\n",
      "ds = gdal.Open(ph)\n",
      "base = ds.ReadAsArray()\n",
      "\n",
      "for i in range(0,6):\n",
      "    phase_array = np.zeros_like(base)\n",
      "    coher_array = np.zeros_like(base)\n",
      "    rmse_array = np.zeros_like(base)\n",
      "    \n",
      "    for j in range(0, 48): # pixelcolumn\n",
      "        for k in range(0,35): # pixelrow\n",
      "        \n",
      "            # Set path for cumulative period of precipitation\n",
      "            # And corresponding period time\n",
      "            cumper = mth[i]\n",
      "            period = prd[i]\n",
      "            paths1 = pth1.replace('XX', str(period))\n",
      "            paths2 = pth2\n",
      "            \n",
      "    \n",
      "            # Set pixelvalues\n",
      "            # TODO: Implementation to read row by row or all-in-one\n",
      "            pixelcolumn = j\n",
      "            pixelrow = k\n",
      "            \n",
      "            # Get values for precipitation based on cumper \n",
      "            # And only update values for NDVI with a new pixel\n",
      "            s_org2 = getvalues(paths2, pixelcolumn, pixelrow, wildcard='CQ')            \n",
      "            if s_org2.mean()<>-99999.0:\n",
      "                s_org1 = getvalues(paths1, pixelcolumn, pixelrow, wildcard='TRMM')                \n",
      "            \n",
      "                # Create dataframe from the two series and apply an outer join            \n",
      "                df1 = pd.DataFrame(s_org1, columns=['prcp'])\n",
      "                df2 = pd.DataFrame(s_org2, columns=['ndvi'])            \n",
      "                df = pd.concat([df1, df2], join='outer', axis=1)\n",
      "                \n",
      "                # Before splitting the signals, first drop eventual NaN values\n",
      "                df = df.dropna()            \n",
      "                s1 = df['prcp']\n",
      "                s2 = df['ndvi']\n",
      "                x = s1.values\n",
      "                y = s2.values\n",
      "                # Extent annual signal to 20 years\n",
      "                \n",
      "                x = np.resize(x, (x.size*20) )\n",
      "                y = np.resize(y, (y.size*20) )\n",
      "                \n",
      "                # Normalise annual signal\n",
      "                x = (x - x.mean())/x.std()\n",
      "                y = (y - y.mean())/y.std()  \n",
      "                #print len(x)\n",
      "                #print len(y)\n",
      "                ml.putArray(\"x\",x)\n",
      "                ml.putArray(\"y\",y)\n",
      "                print 'submit'\n",
      "                ml.eval(\"[s,c,ph,ci,phi] = cmtm(x,y,1,4,1,10,0);\")\n",
      "                ml.eval(\"s = s';c=c';ph=ph';ci=ci';phi=phi';\")\n",
      "                print 'done'\n",
      "                time.sleep(1)\n",
      "                s = ml.getArray(\"s\")\n",
      "                if len(s):\n",
      "                    print 's ok'\n",
      "                    time.sleep(2)\n",
      "                c = ml.getArray(\"c\")\n",
      "                if len(c):\n",
      "                    print 'c ok'\n",
      "                    time.sleep(1)\n",
      "                ph = ml.getArray(\"ph\")\n",
      "                if len(ph):\n",
      "                    print 'ph ok'\n",
      "                    time.sleep(1)\n",
      "                ci = ml.getArray(\"ci\")\n",
      "                if len(ci):\n",
      "                    print 'ci ok'\n",
      "                    time.sleep(1)\n",
      "                phi = ml.getArray(\"phi\")\n",
      "                if len(phi):\n",
      "                    print 'phi ok'\n",
      "                    time.sleep(1)                \n",
      "                \n",
      "                cl = c[(0.0024 < s) & (s <0.0031)].mean()\n",
      "                sl = s[(0.0024 < s) & (s <0.0031)].mean()\n",
      "                phl = ph[(0.0024 < s) & (s <0.0031)].mean() # frequency\n",
      "                phil = phi[(0.0024 < s) & (s <0.0031)].mean() # frequency\n",
      "                phl = phl/(2*np.pi*sl) # time domain\n",
      "                phil = phil/(2*np.pi*sl) # time domain\n",
      "  \n",
      "                #print (rmse, coher, phase) \n",
      "                phase_array[k][j] = phl\n",
      "                coher_array[k][j] = cl\n",
      "                rmse_array[k][j] = phil\n",
      "            else:\n",
      "                phase_array[k][j] = -99999.0\n",
      "                coher_array[k][j] = -99999.0\n",
      "                rmse_array[k][j] = -99999.0\n",
      "            print 'Col',j,'Row', k, 'CumPer', i, 'Phase',phase_array[k][j], 'Coherence', coher_array[k][j], 'RMSE', rmse_array[k][j]\n",
      "                \n",
      "            \n",
      "    folder = r'D:\\Data\\0_DAILY_INTERVAL_NDVI_TRMM\\InnerMongolia\\PLOT_MAPS_2009\\matlab//'\n",
      "    path_phase = folder+'phase_'+str(prd[i])+'.tif'\n",
      "    path_coher = folder+'coherence_'+str(prd[i])+'.tif'\n",
      "    path_rmse = folder+'rmse_'+str(prd[i])+'.tif'\n",
      "\n",
      "    saveRaster(path_phase, phase_array, ds, datatype=6, nan=-99999.0)\n",
      "    saveRaster(path_coher, coher_array, ds, datatype=6, nan=-99999.0)\n",
      "    saveRaster(path_rmse, rmse_array, ds, datatype=6, nan=-99999.0)\n",
      "    \n",
      "    print path_phase\n",
      "    print path_coher\n",
      "    print path_rmse"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Col 0 Row 0 CumPer 0 Phase -99999.0 Coherence -99999.0 RMSE -99999.0\n",
        "Col"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0 Row 1 CumPer 0 Phase -99999.0 Coherence -99999.0 RMSE -99999.0\n",
        "Col"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0 Row 2 CumPer 0 Phase -99999.0 Coherence -99999.0 RMSE -99999.0\n",
        "Col"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0 Row 3 CumPer 0 Phase -99999.0 Coherence -99999.0 RMSE -99999.0\n",
        "Col"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0 Row 4 CumPer 0 Phase -99999.0 Coherence -99999.0 RMSE -99999.0\n",
        "Col"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0 Row 5 CumPer 0 Phase -99999.0 Coherence -99999.0 RMSE -99999.0\n",
        "Col"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0 Row 6 CumPer 0 Phase -99999.0 Coherence -99999.0 RMSE -99999.0\n",
        "Col"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0 Row 7 CumPer 0 Phase -99999.0 Coherence -99999.0 RMSE -99999.0\n",
        "Col"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0 Row 8 CumPer 0 Phase -99999.0 Coherence -99999.0 RMSE -99999.0\n",
        "Col"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0 Row 9 CumPer 0 Phase -99999.0 Coherence -99999.0 RMSE -99999.0\n",
        "Col"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0 Row 10 CumPer 0 Phase -99999.0 Coherence -99999.0 RMSE -99999.0\n",
        "Col"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0 Row 11 CumPer 0 Phase -99999.0 Coherence -99999.0 RMSE -99999.0\n",
        "Col"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0 Row 12 CumPer 0 Phase -99999.0 Coherence -99999.0 RMSE -99999.0\n",
        "Col"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0 Row 13 CumPer 0 Phase -99999.0 Coherence -99999.0 RMSE -99999.0\n",
        "Col"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0 Row 14 CumPer 0 Phase -99999.0 Coherence -99999.0 RMSE -99999.0\n",
        "Col"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0 Row 15 CumPer 0 Phase -99999.0 Coherence -99999.0 RMSE -99999.0\n",
        "Col"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0 Row 16 CumPer 0 Phase -99999.0 Coherence -99999.0 RMSE -99999.0\n",
        "Col"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0 Row 17 CumPer 0 Phase -99999.0 Coherence -99999.0 RMSE -99999.0\n",
        "submit"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "s ok"
       ]
      }
     ],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f, fxx, fyy, fxy = tsa.spectral.get_spectra_bi(x,y, method=dict(this_method='multi_taper_csd', Fs=1./0.4, BW=0.00122135, \n",
      "                                                                adaptive=True, low_bias=True ))\n",
      "plot(f, fxx)\n",
      "plot(f, fyy)\n",
      "plot(f, fxy)\n",
      "xlim([0,0.012])\n",
      "xticks([0.002,0.0022,0.0024,0.0026,0.0028,0.003,0.0032,0.0034,0.0036,0.0038,0.004])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f, ccy = tsa.cohere.coherency(q, csd_method=dict(this_method='multi_taper_csd', Fs=1./0.4, BW=0.00122135, \n",
      "                                                                adaptive=True, low_bias=True ))\n",
      "plot(f,ccy[1][0])\n",
      "xlim([0,0.012])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f, cce = tsa.cohere.coherence(q, csd_method=dict(this_method='multi_taper_csd', Fs=1./0.4, BW=0.00122135, \n",
      "                                                                adaptive=True, low_bias=True ))\n",
      "plot(f,cce[0][1])\n",
      "xlim([0,0.012])\n",
      "ylim([-0.1,1.1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f, p = tsa.cohere.coherency_phase_spectrum(q, csd_method=dict(this_method='multi_taper_csd', Fs=1./0.4, BW=0.00122135, \n",
      "                                                                adaptive=True, low_bias=True ))\n",
      "plot(f,p[0][1])\n",
      "xlim([0,0.012])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c = cce[0][1][(0.0022 < f) & (f <0.0032)]\n",
      "y = p[0][1][(0.0022 < f) & (f <0.0032)]\n",
      "xi = f[(0.0022 < f) & (f <0.0032)]\n",
      "plot(xi,y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy import stats\n",
      "slope, intercept, r_value, p_value, std_err = stats.linregress(xi,y)\n",
      "\n",
      "print 'r value', r_value\n",
      "print  'p_value', p_value\n",
      "print 'standard deviation', std_err\n",
      "\n",
      "line = slope*xi+intercept\n",
      "plot(xi,line,'r-',xi,y,'o')\n",
      "show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mse = ((y - line)**2).mean(axis=None)\n",
      "rmse = math.sqrt(mse)\n",
      "coher = c.mean()\n",
      "phase = y.mean()\n",
      "print (rmse, coher, phase)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.arctan2("
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}